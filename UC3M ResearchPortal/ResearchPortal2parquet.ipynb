{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d75386",
   "metadata": {},
   "source": [
    "# 1. Import libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3da59e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import json  \n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "import pyarrow.parquet as pq\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175319ef",
   "metadata": {},
   "source": [
    "# 2. Define input and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5c5f90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data = Path(\"/export/data_ml4ds/AI4U/Datasets/ResearchPortal/20231005/rawdata/researchportal.uc3m.es/display\")\n",
    "parquet_data = Path(\"/export/data_ml4ds/AI4U/Datasets/ResearchPortal/20231005/parquet\")\n",
    "\n",
    "parquet_data.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0023f66-5af3-4a9f-834f-117f6c02dfad",
   "metadata": {},
   "source": [
    "# 3. Table `researchers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f162c8f-d9f2-4a18-97ef-64c42377ce97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1393/1393 [00:38<00:00, 35.88it/s]\n"
     ]
    }
   ],
   "source": [
    "all_researchers_files = list(raw_data.glob(\"inv*\"))\n",
    "all_researchers = []\n",
    "\n",
    "for file_path in tqdm(all_researchers_files):\n",
    "    if file_path.is_file():\n",
    "        with file_path.open(\"r\") as fin:\n",
    "            content = fin.read()\n",
    "\n",
    "            # Crear un objeto BeautifulSoup\n",
    "            soup = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "            element = soup.find(class_=\"categoriainv\")\n",
    "\n",
    "            # Nombre\n",
    "            try:\n",
    "                element = soup.find('span', {'itemprop': 'name'})\n",
    "                name = element.get_text().strip().title()\n",
    "            except:\n",
    "                name = None\n",
    "            \n",
    "            # Categoría del Investigador\n",
    "            try:\n",
    "                element = soup.find(class_=\"categoriainv\")\n",
    "                cat = element.get_text().split(': ')[1].strip()\n",
    "            except:\n",
    "                cat = None\n",
    "\n",
    "            # ORCID\n",
    "            try:\n",
    "                element = soup.find(class_='individual-orcid')\n",
    "                # Buscar dentro de este elemento el primer enlace y obtener su 'href'\n",
    "                enlace = element.find('a')\n",
    "                if enlace and 'href' in enlace.attrs:\n",
    "                    orcid = enlace['href'].split('/')[-1].strip()\n",
    "            except:\n",
    "                orcid = None\n",
    "\n",
    "            # Scopus\n",
    "            try:\n",
    "                element = soup.find(id='scopusId-noRangeClass-List')\n",
    "                if element:\n",
    "                    enlace = element.find('a')\n",
    "                    if enlace:\n",
    "                        scopus = enlace.get_text().strip()\n",
    "            except:\n",
    "                scopus = None\n",
    "\n",
    "            # Positions\n",
    "            try:\n",
    "                element = soup.find_all(class_='currentPosition')\n",
    "                for el in element:\n",
    "                    if \"Academic Department\" in el.get_text():\n",
    "                        dep = el.find('span', itemprop='name').get_text().strip()\n",
    "                    if \"Research Group\" in el.get_text():\n",
    "                        res_group = el.find('span', itemprop='name').get_text().strip()\n",
    "            except:\n",
    "                dep = None\n",
    "                res_group = None\n",
    "\n",
    "            # Research Areas\n",
    "            try:\n",
    "                element = soup.find('ul', {'id': 'individual-hasResearchArea'})\n",
    "                subject = []\n",
    "                # Si se encuentra el elemento ul, extraer los textos de los elementos li\n",
    "                list_items = element.find_all('li', role=\"listitem\")\n",
    "                for item in list_items:\n",
    "                    subject.append(item.get_text(strip=True))\n",
    "            except:\n",
    "                subject = None\n",
    "\n",
    "            # email\n",
    "            try:\n",
    "                element = soup.find(class_='individual-emails')\n",
    "                email = element.find('a').get_text().strip()\n",
    "            except:\n",
    "                email = None\n",
    "\n",
    "            # Number of publications\n",
    "            try:\n",
    "                element = soup.find(id='publicationsGroup').find_all('a')\n",
    "                element = [el for el in element if el.get('title') == \"resource name\"]\n",
    "                n_publis = len(element)\n",
    "            except:\n",
    "                n_publis = 0\n",
    "\n",
    "            # Projects_IP\n",
    "            try:\n",
    "                element = soup.find(id='RO_0000053-PrincipalInvestigatorRole-List').find_all('a')\n",
    "                element = [el for el in element if el.get('title') == \"activity name\"]\n",
    "                n_IP = len(element)\n",
    "            except:\n",
    "                n_IP = 0\n",
    "\n",
    "            # Projects_noIP\n",
    "            try:\n",
    "                element = soup.find(id='RO_0000053-InvestigatorRole-List').find_all('a')\n",
    "                element = [el for el in element if el.get('title') == \"activity name\"]\n",
    "                n_noIP = len(element)\n",
    "            except:\n",
    "                n_noIP = 0\n",
    "\n",
    "        all_researchers.append([file_path.stem, name, email, cat, orcid, dep, res_group, subject, n_publis, n_IP, n_noIP])\n",
    "\n",
    "columns = ['invID', 'Name', 'Email', 'Category', 'ORCID', 'Department', 'Research Group', 'Subjects', 'no Publis', 'Projects IP', 'Projects no IP']\n",
    "df = pd.DataFrame(all_researchers, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd62326-7127-4eac-91ab-866bc177b0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Researchers 1393\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>Category</th>\n",
       "      <th>ORCID</th>\n",
       "      <th>Department</th>\n",
       "      <th>Research Group</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>no Publis</th>\n",
       "      <th>Projects IP</th>\n",
       "      <th>Projects no IP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inv17981</td>\n",
       "      <td>Gonzalez-Cuellar Serrano, Maria Luisa</td>\n",
       "      <td>mlgonzal@der-pu.uc3m.es</td>\n",
       "      <td>Full Professor</td>\n",
       "      <td>0000-0002-0999-7711</td>\n",
       "      <td>Public State Law</td>\n",
       "      <td>Research Group on Financial and Tax Law</td>\n",
       "      <td>[Law]</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inv35577</td>\n",
       "      <td>Quintana Montero, David</td>\n",
       "      <td>dquintan@inf.uc3m.es</td>\n",
       "      <td>Associate Professor</td>\n",
       "      <td>0000-0003-0320-1695</td>\n",
       "      <td>Computer Science and Engineering</td>\n",
       "      <td>Evolutionary Computation and Neural Networks (...</td>\n",
       "      <td>[Computer Science, Economics, Robotics and Ind...</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inv48535</td>\n",
       "      <td>Varela Garcia, Nicolas</td>\n",
       "      <td>nvarela@pa.uc3m.es</td>\n",
       "      <td>PhD Candidate</td>\n",
       "      <td>0000-0002-9135-5338</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>Histories of Global Latin Capitalisms (H-GLACIAL)</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inv40978</td>\n",
       "      <td>Gutierrez Fernandez, Eric</td>\n",
       "      <td>egutie1@ing.uc3m.es</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>0000-0002-2901-441X</td>\n",
       "      <td>Electronic Technology</td>\n",
       "      <td>Histories of Global Latin Capitalisms (H-GLACIAL)</td>\n",
       "      <td>[Education, Electronics, Telecommunications]</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inv35940</td>\n",
       "      <td>Gonzalez Rodriguez, Pedro</td>\n",
       "      <td>pgonzale@ing.uc3m.es</td>\n",
       "      <td>Associate Professor</td>\n",
       "      <td>0000-0002-1378-273X</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Grupo de Métodos Numéricos y Aplicaciones</td>\n",
       "      <td>[Biology and Biomedicine, Fission, Mathematics...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      invID                                   Name                    Email  \\\n",
       "0  inv17981  Gonzalez-Cuellar Serrano, Maria Luisa  mlgonzal@der-pu.uc3m.es   \n",
       "1  inv35577                Quintana Montero, David     dquintan@inf.uc3m.es   \n",
       "2  inv48535                 Varela Garcia, Nicolas       nvarela@pa.uc3m.es   \n",
       "3  inv40978              Gutierrez Fernandez, Eric      egutie1@ing.uc3m.es   \n",
       "4  inv35940              Gonzalez Rodriguez, Pedro     pgonzale@ing.uc3m.es   \n",
       "\n",
       "              Category                ORCID                        Department  \\\n",
       "0       Full Professor  0000-0002-0999-7711                  Public State Law   \n",
       "1  Associate Professor  0000-0003-0320-1695  Computer Science and Engineering   \n",
       "2        PhD Candidate  0000-0002-9135-5338                   Social Sciences   \n",
       "3  Assistant Professor  0000-0002-2901-441X             Electronic Technology   \n",
       "4  Associate Professor  0000-0002-1378-273X                       Mathematics   \n",
       "\n",
       "                                      Research Group  \\\n",
       "0            Research Group on Financial and Tax Law   \n",
       "1  Evolutionary Computation and Neural Networks (...   \n",
       "2  Histories of Global Latin Capitalisms (H-GLACIAL)   \n",
       "3  Histories of Global Latin Capitalisms (H-GLACIAL)   \n",
       "4          Grupo de Métodos Numéricos y Aplicaciones   \n",
       "\n",
       "                                            Subjects  no Publis  Projects IP  \\\n",
       "0                                              [Law]         41            7   \n",
       "1  [Computer Science, Economics, Robotics and Ind...         37            7   \n",
       "2                                               None          0            0   \n",
       "3       [Education, Electronics, Telecommunications]         27            4   \n",
       "4  [Biology and Biomedicine, Fission, Mathematics...         26            1   \n",
       "\n",
       "   Projects no IP  \n",
       "0               5  \n",
       "1               8  \n",
       "2               0  \n",
       "3               7  \n",
       "4               6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of Researchers\", len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf160540-6b13-4f57-b8c8-9550aae5cf33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1393 entries, 0 to 1392\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   invID           1393 non-null   object\n",
      " 1   Name            1393 non-null   object\n",
      " 2   Email           1278 non-null   object\n",
      " 3   Category        1380 non-null   object\n",
      " 4   ORCID           1150 non-null   object\n",
      " 5   Department      1393 non-null   object\n",
      " 6   Research Group  1393 non-null   object\n",
      " 7   Subjects        1113 non-null   object\n",
      " 8   no Publis       1393 non-null   int64 \n",
      " 9   Projects IP     1393 non-null   int64 \n",
      " 10  Projects no IP  1393 non-null   int64 \n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 119.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a824b59d-d09d-470b-af08-5034c3e5a8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_parquet(parquet_data.joinpath('researchers.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0056f75",
   "metadata": {},
   "source": [
    "# 4. Tables `publications` and `researchers_publications`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c393b43-656c-49ad-beae-2279feccb79b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53063/53063 [09:15<00:00, 95.58it/s] \n"
     ]
    }
   ],
   "source": [
    "all_activities = list(raw_data.glob(\"act*\"))\n",
    "\n",
    "all_publis = []\n",
    "res_publis = []\n",
    "\n",
    "nact = 0\n",
    "\n",
    "for file_path in tqdm(all_activities):\n",
    "    if file_path.is_file():\n",
    "        with file_path.open(\"r\") as fin:\n",
    "            content = fin.read()\n",
    "\n",
    "            # Crear un objeto BeautifulSoup\n",
    "            soup = BeautifulSoup(content, \"html.parser\")\n",
    "            activity_type = soup.find(class_=\"display-title\").get_text().strip()\n",
    "            if activity_type in ['Articles', 'Book Chapters', 'Conference Contributions']:\n",
    "                \n",
    "                # Título\n",
    "                try: \n",
    "                    title = soup.title.get_text()\n",
    "                except:\n",
    "                    title = None\n",
    "                \n",
    "                # DOI\n",
    "                try:\n",
    "                    doi = soup.find('a', title=\"Digital Object Identifier (DOI)\").get_text()\n",
    "                except:\n",
    "                    doi = None\n",
    "\n",
    "                # Year\n",
    "                try:\n",
    "                    year = int(soup.find(id='dateTimeValue-DateTimeValue-List').get_text().strip().split()[-1])\n",
    "                except:\n",
    "                    year = np.nan\n",
    "\n",
    "                # Abstract\n",
    "                try:\n",
    "                    abstract = soup.find(id='abstract-noRangeClass-List').get_text().strip()\n",
    "                except:\n",
    "                    abstract = None\n",
    "\n",
    "                # Abstract\n",
    "                try:\n",
    "                    keywords = soup.find(id='freetextKeyword-noRangeClass-List').get_text().strip()\n",
    "                except:\n",
    "                    keywords = None\n",
    "\n",
    "                # Autores\n",
    "                try:\n",
    "                    authors = soup.find('ul', id='relatedBy-Authorship-List').find_all('li', role=\"listitem\")\n",
    "                    for idx,el in enumerate(authors):\n",
    "                        if el.find('a'):\n",
    "                            res_publis.append([file_path.stem, el.find('a')['href'].strip().split('.html')[0], idx+1])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                all_publis.append([file_path.stem, activity_type, title, abstract, keywords, doi, year])\n",
    "\n",
    "columns = ['actID', 'ActivityType', 'Title', 'Abstract', 'Keywords', 'DOI', 'Year']\n",
    "df_publis = pd.DataFrame(all_publis, columns=columns)\n",
    "\n",
    "columns = ['actID', 'invID', 'Order']\n",
    "df_res_publis = pd.DataFrame(res_publis, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35fd842f-3ffe-4f4f-84f3-a181014e8dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Publis 40243\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actID</th>\n",
       "      <th>ActivityType</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>act398486</td>\n",
       "      <td>Conference Contributions</td>\n",
       "      <td>Implementation of 2D Domain Decomposition in t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act501456</td>\n",
       "      <td>Conference Contributions</td>\n",
       "      <td>Accessibility Guidelines for Tactile Displays ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://doi.org/10.1007/978-3-319-94274-2_29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>act523614</td>\n",
       "      <td>Book Chapters</td>\n",
       "      <td>En la víspera del esplendor: el Washington Cit...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>act324958</td>\n",
       "      <td>Articles</td>\n",
       "      <td>Practical SPI Planning</td>\n",
       "      <td>This paper presents a practical procedure name...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://doi.org/10.1007/978-3-540-85936-9_8</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>act492251</td>\n",
       "      <td>Articles</td>\n",
       "      <td>Fractional-order PID control of a chopper-fed ...</td>\n",
       "      <td>In this paper, a dynamic control mechanism is ...</td>\n",
       "      <td>chopper-fed dc motor drive; fractional-order p...</td>\n",
       "      <td>https://doi.org/10.1007/s00500-017-2677-5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actID              ActivityType  \\\n",
       "0  act398486  Conference Contributions   \n",
       "1  act501456  Conference Contributions   \n",
       "2  act523614             Book Chapters   \n",
       "3  act324958                  Articles   \n",
       "4  act492251                  Articles   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Implementation of 2D Domain Decomposition in t...   \n",
       "1  Accessibility Guidelines for Tactile Displays ...   \n",
       "2  En la víspera del esplendor: el Washington Cit...   \n",
       "3                             Practical SPI Planning   \n",
       "4  Fractional-order PID control of a chopper-fed ...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  This paper presents a practical procedure name...   \n",
       "4  In this paper, a dynamic control mechanism is ...   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4  chopper-fed dc motor drive; fractional-order p...   \n",
       "\n",
       "                                            DOI  Year  \n",
       "0                                          None  2012  \n",
       "1  https://doi.org/10.1007/978-3-319-94274-2_29  2018  \n",
       "2                                          None  2019  \n",
       "3   https://doi.org/10.1007/978-3-540-85936-9_8  2008  \n",
       "4     https://doi.org/10.1007/s00500-017-2677-5  2017  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of Publis\", len(df_publis))\n",
    "df_publis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "086f744f-9e88-450c-a1e4-e211c9c8bcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40243 entries, 0 to 40242\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   actID         40243 non-null  object\n",
      " 1   ActivityType  40243 non-null  object\n",
      " 2   Title         40243 non-null  object\n",
      " 3   Abstract      15625 non-null  object\n",
      " 4   Keywords      15489 non-null  object\n",
      " 5   DOI           16772 non-null  object\n",
      " 6   Year          40243 non-null  int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_publis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9d3fa0-3074-4538-b65b-7caa1d9ad4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_surrogates(text):\n",
    "    if text:\n",
    "        try:\n",
    "            # Reemplazar los caracteres de sustitución, o simplemente eliminarlos\n",
    "            return text.encode('utf-16', 'surrogatepass').decode('utf-16')\n",
    "            return text\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "# Aplicar esta función a todas las columnas de texto en tu DataFrame\n",
    "df_publis['Abstract'] = df_publis['Abstract'].apply(clean_surrogates)\n",
    "df_publis.to_parquet(parquet_data.joinpath('publications.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c154f746-b52d-4059-9357-cf069b87720e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Signatures 48977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actID</th>\n",
       "      <th>invID</th>\n",
       "      <th>Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>act398486</td>\n",
       "      <td>inv17843</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act501456</td>\n",
       "      <td>inv15183</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>act523614</td>\n",
       "      <td>inv18754</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>act324958</td>\n",
       "      <td>inv16849</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>act324958</td>\n",
       "      <td>inv15355</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actID     invID  Order\n",
       "0  act398486  inv17843      4\n",
       "1  act501456  inv15183      2\n",
       "2  act523614  inv18754      1\n",
       "3  act324958  inv16849      2\n",
       "4  act324958  inv15355      3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of Signatures\", len(df_res_publis))\n",
    "df_res_publis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f77a975-2e63-4fc7-a7dc-7d12bc801aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48977 entries, 0 to 48976\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   actID   48977 non-null  object\n",
      " 1   invID   48977 non-null  object\n",
      " 2   Order   48977 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_res_publis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa9cf98f-7ee7-48ba-a224-3fb1b0308d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_res_publis.to_parquet(parquet_data.joinpath('researchers_publications.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186345a2-d1aa-4c74-b627-72359aaec085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1196fb-a5bf-4e80-9e90-77f612f7deca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a0887-2b4d-4917-b08a-fcb7bfb22cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3727423-eafe-4d72-b2af-f92863ff63dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b447bd-28c7-49d5-aa72-6c9df03c57b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38beb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access each url given the ID\n",
    "for n, inv in enumerate(inv_act):\n",
    "    \n",
    "    print(f'\\nActivity {n+1} out of {len(inv_act)}')\n",
    "    inv_file = Path.cwd().joinpath(f'researchportal.uc3m.es/display/act{inv}.html')\n",
    "    auth_url = f'file:///{inv_file}'\n",
    "    driver.get(auth_url)\n",
    "    \n",
    "    # section: articles, book chapters, conference contributions, working papers, projects, ...\n",
    "    section = driver.find_element(By.CLASS_NAME, 'display-title').text\n",
    "    valid_sections = [\"Articles\", \"Book Chapters\", \"Conference Contributions\", \"Working Papers\"]\n",
    "            \n",
    "    try:\n",
    "        if section in valid_sections:\n",
    "            resID = inv\n",
    "            # print(\"Resource ID: \", resID)\n",
    "            \n",
    "            # Title of the activity\n",
    "            title = driver.find_element(By.CLASS_NAME, 'fn').text\n",
    "            for section_name in valid_sections:\n",
    "                if title.endswith(section_name):\n",
    "                    title = title.rsplit(section_name, 1)[0].strip()\n",
    "                    # print(\"Title: \", title)\n",
    "                    break  \n",
    "                    \n",
    "            # Publication date\n",
    "            try:         \n",
    "                publication_date = driver.find_element(By.XPATH, '//h3[@id=\"dateTimeValue\"]/following-sibling::ul/li').text.strip()\n",
    "                # print(\"Publication Date: \", publication_date)\n",
    "            except:\n",
    "                publication_date = \"\"\n",
    "                # print(\"Publication Date: \", publication_date)\n",
    "\n",
    "                \n",
    "            # Publisher/magazine\n",
    "            try: \n",
    "                if section == \"Articles\":\n",
    "                    publication_venue = driver.find_element(By.XPATH, '//h3[@id=\"hasPublicationVenue\"]/following-sibling::ul/li/a').text.strip()\n",
    "                    # print(\"Publication Venue: \", publication_venue)\n",
    "                    \n",
    "                elif section in [\"Book Chapters\", \"Conference Contributions\", \"Working Papers\"]:\n",
    "                    publication_venue = driver.find_element(By.XPATH, '//h3[@id=\"publisher\"]/following-sibling::ul/li/a').text.strip()\n",
    "                    # print(\"Publisher:\", publication_venue)\n",
    "                    \n",
    "            except:\n",
    "                publication_venue = \"\"\n",
    "                # print(\"Publisher:\", publication_venue)\n",
    "\n",
    "                    \n",
    "            # DOI number\n",
    "            try: \n",
    "                doi = driver.find_element(By.XPATH, '//h3[@id=\"doi\"]/following-sibling::ul/li/a').text.strip()\n",
    "                # print(\"DOI:\", doi)\n",
    "            except: \n",
    "                doi = \"\"\n",
    "                # print(\"DOI:\", doi)\n",
    "\n",
    "                \n",
    "            # Abstract\n",
    "            try:\n",
    "                abstract = driver.find_element(By.XPATH, '//h3[@id=\"abstract\"]/following-sibling::ul/li').text.strip()\n",
    "                # print(\"Abstract: \", abstract)\n",
    "            except:\n",
    "                abstract = \"\"\n",
    "                # print(\"Abstract: \", abstract)\n",
    "\n",
    "\n",
    "                \n",
    "            # Keywords\n",
    "            try:\n",
    "                keywords_list = []\n",
    "                keywords = driver.find_element(By.XPATH, '//h3[@id=\"freetextKeyword\"]/following-sibling::ul/li').text.strip()\n",
    "                # Split the string using commas\n",
    "                keywords_split_by_comma = keywords.split(',')\n",
    "\n",
    "                # Split each resulting keyword using semicolons\n",
    "                keywords_list = [keyword.strip() for keyword_with_semicolon in keywords_split_by_comma for keyword in keyword_with_semicolon.split(';')]\n",
    "                # print(\"Keywords List: \", keywords_list)\n",
    "            except:\n",
    "                keywords_list = []\n",
    "                # print(\"Keywords List: \", keywords_list)\n",
    "\n",
    "                \n",
    "            # Research Areas\n",
    "            try: \n",
    "                research_areas = driver.find_elements(By.XPATH, '//h3[@id=\"hasResearchArea\"]/following-sibling::ul/li')\n",
    "                research_areas = [element.text.strip() for element in research_areas]\n",
    "                # print(\"Research Areas: \", research_areas)\n",
    "            except:\n",
    "                research_areas = []\n",
    "                # print(\"Research Areas: \", research_areas)\n",
    "\n",
    "            \n",
    "            # Authors IDs (if there is any ID)\n",
    "            try:\n",
    "                # Locate the parent <article> element\n",
    "                article_element = driver.find_element(By.XPATH, '//article[@class=\"property\" and @role=\"article\"]')\n",
    "                # Locate the <ul> element within the article for authors\n",
    "                authors_list = article_element.find_element(By.XPATH, '//ul[@role=\"list\" and @id=\"relatedBy-Authorship-List\"]')\n",
    "\n",
    "                # Get all <li> elements within the authors list\n",
    "                author_items = authors_list.find_elements(By.XPATH, 'li')\n",
    "\n",
    "                # Extract the author IDs\n",
    "                author_ids = []\n",
    "\n",
    "                for author_order, author_item in enumerate(author_items, start=1):\n",
    "                    author_name = author_item.text.strip()\n",
    "                    # print(\"Author: \", author_name, \"with order:\", author_order)\n",
    "                    href_attribute = author_item.find_elements(By.XPATH, 'a')\n",
    "                    \n",
    "                    for invID in href_attribute:\n",
    "                        invID = invID.get_attribute('href').split(\"inv\")[1]\n",
    "                        author_ids.append(invID)\n",
    "\n",
    "                        inv_pub.append({'invID': invID, 'pubID': resID, 'orderID': author_order})\n",
    "        \n",
    "                # print(\"Valid Researchers IDs: \", author_ids)\n",
    "\n",
    "            except:\n",
    "                author_ids = []\n",
    "    \n",
    "            publications.append({'resID': resID, 'section': section, 'title': title, 'doi': doi, 'publication_date': publication_date, 'publisher': publication_venue, 'abstract': abstract, 'keywords': keywords_list, 'research_areas': research_areas})\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if not n%100:\n",
    "        with open(relative_path + 'outputs/publications.json', 'w') as f:\n",
    "            json.dump(publications, f, indent=4)\n",
    "        with open(relative_path + 'outputs/inv_pub.json', 'w') as f:\n",
    "            json.dump(inv_pub, f, indent=4)\n",
    "            \n",
    "with open(relative_path + 'outputs/publications.json', 'w') as f:\n",
    "    json.dump(publications, f, indent=4)\n",
    "with open(relative_path + 'outputs/inv_pub.json', 'w') as f:\n",
    "    json.dump(inv_pub, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4166533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    # SCRAPING PROJECTS' INFORMATION\n",
    "    projects = []\n",
    "    try:\n",
    "        pub_list = driver.find_element(By.ID,'projectsGroup').find_elements(By.CLASS_NAME, 'property')\n",
    "        for section in pub_list:\n",
    "            # section_title: 'principal researcher on', 'researcher on'\n",
    "            section_title = section.find_element(By.TAG_NAME, 'h3').text\n",
    "            sections = []\n",
    "            for p in section.find_elements(By.TAG_NAME,'li'):\n",
    "                element = p.find_element(By.TAG_NAME, 'a')\n",
    "                # resource ID\n",
    "                resID = element.get_attribute('href').split('/')[-1][3:]\n",
    "                \n",
    "                try:\n",
    "                    inv_file = Path.cwd().joinpath(f'researchportal.uc3m.es/display/act{resID}.html')\n",
    "                    auth_url = f'file:///{inv_file}'\n",
    "                    driver2.get(auth_url)\n",
    "\n",
    "                    \n",
    "                    property_list = driver2.find_elements(By.CLASS_NAME, 'property')\n",
    "\n",
    "                    # Iterar a través de los elementos 'property' para encontrar el abstract\n",
    "                    for article in property_list:\n",
    "                        abstract = \"\"\n",
    "\n",
    "                        # Verificar si el ID del elemento contiene 'abstract'\n",
    "                        abstract_elements = article.find_elements(By.ID, \"abstract-noRangeClass-List\")\n",
    "                        if abstract_elements:\n",
    "                            # Extraer el texto del elemento\n",
    "                            abstract = abstract_elements[0].text\n",
    "                except:\n",
    "                    abstract = ''\n",
    "                    \n",
    "                title = element.text\n",
    "                year = p.find_element(By.TAG_NAME, 'span').text\n",
    "                \n",
    "                                \n",
    "                try:\n",
    "                    funding_entity = p.find_element(By.XPATH, './/a[@title=\"awarded by\"]').text\n",
    "                \n",
    "                except:\n",
    "                    funding_entity = \"\"\n",
    "                    \n",
    "                sections.append({'resID':resID, 'title':title, 'year':year, 'funding_entity': funding_entity, 'abstract': abstract})\n",
    "            projects.append((section_title, sections))\n",
    "    except:\n",
    "        pass\n",
    "    projects.append({'author':inv, 'projects':dict(projects)})\n",
    "  \n",
    "    \n",
    "    # Conditional check and savings (Periodic backups)\n",
    "    if not n%100:\n",
    "        with open(relative_path + 'outputs/researchers.json', 'w') as f:\n",
    "            json.dump(researchers, f, indent=4)\n",
    "        with open(relative_path + 'outputs/publications.json', 'w') as f:\n",
    "            json.dump(publications_data, f, indent=4)\n",
    "        with open(relative_path + 'outputs/projects.json', 'w') as f:\n",
    "            json.dump(projects, f, indent=4)\n",
    "\n",
    "# Always saving (Periodic backups)\n",
    "\n",
    "with open(relative_path + 'outputs/researchers.json', 'w') as f:\n",
    "    json.dump(researchers, f, indent=4)\n",
    "with open(relative_path + 'outputs/publications.json', 'w') as f:\n",
    "    json.dump(publications, f, indent=4)\n",
    "with open(relative_path + 'outputs/projects.json', 'w') as f:\n",
    "    json.dump(projects, f, indent=4) \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404888ac",
   "metadata": {},
   "source": [
    "# Process JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44498e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json(obj):\n",
    "    '''\n",
    "    Function to process json recursively\n",
    "    '''\n",
    "    resources = []\n",
    "    auth_res = []\n",
    "    author = ''\n",
    "    def process(obj, objType='', author=''):\n",
    "        if isinstance(obj, dict):\n",
    "            for k, v in obj.items():     \n",
    "                if k == 'author':\n",
    "                    author = v\n",
    "                if k == 'title':\n",
    "                    d = {'type':objType.strip()}\n",
    "                    d.update(obj)\n",
    "                    resources.append(d)\n",
    "                    auth_res.append((author, obj['resID']))\n",
    "                else:\n",
    "                    if isinstance(v, (dict, list)):\n",
    "                        process(v, k, author)\n",
    "        elif isinstance(obj, list):\n",
    "            for el in obj:\n",
    "                process(el, objType, author)\n",
    "    process(obj)\n",
    "    return resources, auth_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628ea67",
   "metadata": {},
   "source": [
    "# Formating our dataset and completing abstracts with 'scopus' database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f61c462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Regular expression to extract DOI from the URL\n",
    "doi_pattern = r'https://doi\\.org/(?:http://dx\\.doi\\.org/)?(.+)'\n",
    "\n",
    "# Extract DOI values from URLs in the 'doi' column\n",
    "df_resources['doi'] = df_resources['doi'].str.extract(doi_pattern)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d069652b",
   "metadata": {},
   "source": [
    "### Formating 'df_resources' database: homogenizing NAs and filtering observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Homogenizing the NAs to the same format\n",
    "# Lista de nombres de las columnas en las que deseas reemplazar los valores nulos o vacíos por NaN\n",
    "columns_to_process = ['doi', 'title', 'year', 'abstract', 'funding_entity', 'type']\n",
    "\n",
    "# Iterar sobre las columnas y reemplazar los valores nulos o vacíos por NaN\n",
    "for column in columns_to_process:\n",
    "    df_resources[column] = df_resources[column].apply(lambda x: np.nan if x in [None, ''] else x)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Filter the dataset by observations that have at least doi or at least abstract (so, an observation that can be completed if it has no abstract)\n",
    "filtered_df_resources = df_resources[(df_resources['doi'].isna() & ~df_resources['abstract'].isna()) | (~df_resources['doi'].isna() & ~df_resources['abstract'].isna()) | (~df_resources['doi'].isna() & df_resources['abstract'].isna())]\n",
    "filtered_df_resources.reset_index(drop=True, inplace=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75dc47",
   "metadata": {},
   "source": [
    "### Formating Scopus database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807db5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data = pd.read_parquet('/Users/lcsanchez/Desktop/Research/Scopus/scopus_data.parquet')\n",
    "\n",
    "filtered_data = data[['doi', 'description']]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87bbc1a",
   "metadata": {},
   "source": [
    "### Joining databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e830c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Perform a left join on 'doi' column\n",
    "merged_df = pd.merge(filtered_df_resources, filtered_data, on='doi', how='left')\n",
    "#merged_df\n",
    "\n",
    "# Llenar NaN en la columna 'abstract' con el valor del abstract de SCOPUS ('description' column) si 'abstract' está vacía\n",
    "merged_df['abstract'] = merged_df['abstract'].combine_first(merged_df['description'])\n",
    "\n",
    "# Eliminamos los duplicados\n",
    "merged_df.drop_duplicates(subset='resID', keep='first', inplace=True)\n",
    "\n",
    "merged_df = merged_df.drop(columns=['description'])\n",
    "\n",
    "# Save the merged table as a CSV file\n",
    "merged_df.to_csv(relative_path + 'outputs/merged_table.csv', index=False)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
