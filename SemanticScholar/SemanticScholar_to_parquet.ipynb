{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e420d98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47791f9f",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e00d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from configparser import ConfigParser\n",
    "from pathlib import Path\n",
    "import pyspark.sql.functions as F\n",
    "#import requests\n",
    "from pyspark.sql.types import ArrayType, StringType, BooleanType, IntegerType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbb4ea",
   "metadata": {},
   "source": [
    "## 2. Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0e75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories\n",
    "#\n",
    "# Relevant directories are read from the config file:\n",
    "# dir_data:    full path to hdfs directory where the raw data .gz files are stored\n",
    "# dir_parquet: full path to hdfs directory where the parquet tables will be stored\n",
    "# version:     Version of Semantic Scholar that is being processed\n",
    "#              for information purposes only\n",
    "\n",
    "# cf = ConfigParser()\n",
    "# cf.read(\"../config.cf\")\n",
    "\n",
    "# dir_data = Path(cf.get(\"spark\", \"dir_data\"))\n",
    "# dir_parquet = Path(cf.get(\"spark\", \"dir_parquet\"))\n",
    "# version = cf.get(\"spark\", \"version\")\n",
    "# dir_pdfs = Path(cf.get(\"spark\", \"dir_pdfs\"))\n",
    "\n",
    "dir_data = Path('/export/data_ml4ds/AI4U/Datasets/semanticscholar/20240730/rawdata')\n",
    "dir_parquet = Path('/export/data_ml4ds/AI4U/Datasets/semanticscholar/20240730/parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83cb265-5a32-4433-9d95-bfcadc36a1bb",
   "metadata": {},
   "source": [
    "## 3. Configuration hdfs\n",
    "\n",
    "**Files will be read from and saved to NFS. Skip this section entirely !**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c5c63-5006-476f-af87-3d264a219c92",
   "metadata": {},
   "source": [
    "It is not possible to listdir() directly using Path as it is a hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea5614-5873-46c8-bb95-117a74bf75eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"# Configuration hdfs\n",
    "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "hdfs_dir_parquet = spark._jvm.org.apache.hadoop.fs.Path(dir_parquet.as_posix())\n",
    "# Create output directories if they do not exist\n",
    "# !hadoop dfs ...\n",
    "# !hadoop dfs -put 20220201 /export/ml4ds/IntelComp/Datalake/SemanticScholar/\n",
    "\n",
    "if not fs.exists(hdfs_dir_parquet):\n",
    "    fs.mkdirs(hdfs_dir_parquet)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54362c14-5c9a-4941-a18a-f1137ed2c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Configuration hdfs\n",
    "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "hdfs_dir_data = spark._jvm.org.apache.hadoop.fs.Path(dir_data.as_posix())\n",
    "\n",
    "print(hdfs_dir_data)\n",
    "\n",
    "# Get selected version\n",
    "releases = sorted(\n",
    "    [\n",
    "        f.getPath().getName()\n",
    "        for f in fs.listStatus(hdfs_dir_data)\n",
    "        if f.isDirectory() and f.getPath().getName().isdigit()\n",
    "    ]\n",
    ")\n",
    "version = version.replace(\"-\", \"\")\n",
    "if version == \"last\":\n",
    "    version = releases[-1]\n",
    "if version not in releases:\n",
    "    print(f\"Version {version} not found\")\n",
    "    print(f\"Available versions: {releases}\")\n",
    "\n",
    "hdfs_dir_data_files = spark._jvm.org.apache.hadoop.fs.Path(\n",
    "    dir_data.joinpath(version).as_posix()\n",
    ")\n",
    "hdfs_dir_parquet = spark._jvm.org.apache.hadoop.fs.Path(dir_parquet.as_posix())\n",
    "hdfs_dir_version = spark._jvm.org.apache.hadoop.fs.Path(\n",
    "    dir_parquet.joinpath(version).as_posix()\n",
    ")\n",
    "\n",
    "# Create output directories if they do not exist\n",
    "# !hadoop dfs ...\n",
    "# !hadoop dfs -put 20220201 /export/ml4ds/IntelComp/Datalake/SemanticScholar/\n",
    "\n",
    "if not fs.exists(hdfs_dir_parquet):\n",
    "    fs.mkdirs(hdfs_dir_parquet)\n",
    "\n",
    "if not fs.exists(hdfs_dir_version):\n",
    "    fs.mkdirs(hdfs_dir_version)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ddd7c-5f60-4f06-b41e-746c2b21eaed",
   "metadata": {},
   "source": [
    "## 4. Import tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e957624d-9793-4900-ba01-9397f58434d1",
   "metadata": {},
   "source": [
    "### 4.1. Table **`papers`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a4989a1-4c1e-4570-b21b-30c841d8391c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers available: 220006291\n",
      "root\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- authorId: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |-- citationcount: long (nullable = true)\n",
      " |-- corpusid: long (nullable = true)\n",
      " |-- externalids: struct (nullable = true)\n",
      " |    |-- ACL: string (nullable = true)\n",
      " |    |-- ArXiv: string (nullable = true)\n",
      " |    |-- CorpusId: string (nullable = true)\n",
      " |    |-- DBLP: string (nullable = true)\n",
      " |    |-- DOI: string (nullable = true)\n",
      " |    |-- MAG: string (nullable = true)\n",
      " |    |-- PubMed: string (nullable = true)\n",
      " |    |-- PubMedCentral: string (nullable = true)\n",
      " |-- influentialcitationcount: long (nullable = true)\n",
      " |-- isopenaccess: boolean (nullable = true)\n",
      " |-- journal: struct (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- pages: string (nullable = true)\n",
      " |    |-- volume: string (nullable = true)\n",
      " |-- publicationdate: string (nullable = true)\n",
      " |-- publicationtypes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- publicationvenueid: string (nullable = true)\n",
      " |-- referencecount: long (nullable = true)\n",
      " |-- s2fieldsofstudy: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- category: string (nullable = true)\n",
      " |    |    |-- source: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- venue: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------\n",
      " authors                  | [{6335557, P. Foelsch}]                                                                                      \n",
      " citationcount            | 1                                                                                                            \n",
      " corpusid                 | 80809568                                                                                                     \n",
      " externalids              | {null, null, 80809568, null, 10.1016/J.NEURENF.2012.05.027, 2332503270, null, null}                          \n",
      " influentialcitationcount | 0                                                                                                            \n",
      " isopenaccess             | false                                                                                                        \n",
      " journal                  | {, null, }                                                                                                   \n",
      " publicationdate          | 2012-07-01                                                                                                   \n",
      " publicationtypes         | null                                                                                                         \n",
      " publicationvenueid       | null                                                                                                         \n",
      " referencecount           | 0                                                                                                            \n",
      " s2fieldsofstudy          | [{Philosophy, s2-fos-model}, {Psychology, s2-fos-model}, {Medicine, external}, {Biology, external}]          \n",
      " title                    | The essentials of identity â€“ differentiating normal from pathological                                        \n",
      " url                      | https://www.semanticscholar.org/paper/6d35ab3955b1beb231a276d3fec0914fe903d71a                               \n",
      " venue                    |                                                                                                              \n",
      " year                     | 2012                                                                                                         \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------------------------------\n",
      " authors                  | [{4347073, Antje Hoenen}]                                                                                    \n",
      " citationcount            | 0                                                                                                            \n",
      " corpusid                 | 81441234                                                                                                     \n",
      " externalids              | {null, null, 81441234, null, null, 33193565, null, null}                                                     \n",
      " influentialcitationcount | 0                                                                                                            \n",
      " isopenaccess             | false                                                                                                        \n",
      " journal                  | {, null, }                                                                                                   \n",
      " publicationdate          | 2009-03-01                                                                                                   \n",
      " publicationtypes         | null                                                                                                         \n",
      " publicationvenueid       | null                                                                                                         \n",
      " referencecount           | 0                                                                                                            \n",
      " s2fieldsofstudy          | [{Medicine, s2-fos-model}, {Biology, s2-fos-model}, {Biology, external}]                                     \n",
      " title                    | The Interferon-Induced Antiviral Protein MxA: Functional and Therapeutic Aspects Relating to Virus Infection \n",
      " url                      | https://www.semanticscholar.org/paper/07e49eeb3a60db9b9e8f39ac98889b922aea441c                               \n",
      " venue                    |                                                                                                              \n",
      " year                     | 2009                                                                                                         \n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 190 ms, sys: 19.8 ms, total: 210 ms\n",
      "Wall time: 7min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dir_papers = dir_data.joinpath('papers')\n",
    "df_papers = spark.read.json('file:///' + dir_papers.as_posix())\n",
    "\n",
    "#We drop corrupt records\n",
    "df_papers = df_papers.cache()\n",
    "df_papers = df_papers.where(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
    "\n",
    "print('Number of papers available:', df_papers.count())\n",
    "df_papers.printSchema()\n",
    "df_papers.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec055d31-5395-4bf2-866c-b3e79ddb9599",
   "metadata": {},
   "source": [
    "<span style=\"background-color:yellow;\">The following code is used to count how many papers of each type are there in the dataset. It is very inefficient probably, but it works nevertheless.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15b3939-0e97-49b0-aff8-8f749bd0fe0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'JournalArticle': 48373755, 'Review': 15641356, 'Conference': 4396499, 'Study': 2339597, 'CaseReport': 2285570, 'LettersAndComments': 1564083, 'Editorial': 714480, 'ClinicalTrial': 581207, 'Book': 385829, 'News': 241762, 'MetaAnalysis': 105257, 'Dataset': 1075})\n"
     ]
    }
   ],
   "source": [
    "tipos = df_papers.where(F.col(\"publicationtypes\").isNotNull()).select('publicationtypes').collect()\n",
    "tipos = [el[0] for el in tipos]\n",
    "tipos = [item for sublist in tipos for item in sublist]\n",
    "\n",
    "from collections import Counter\n",
    "counts = Counter(tipos)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e35bca6-2741-40f8-b492-af3a4f1a5afa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- S2Url: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- pmid: string (nullable = true)\n",
      " |-- magId: string (nullable = true)\n",
      " |-- externalids: struct (nullable = true)\n",
      " |    |-- ACL: string (nullable = true)\n",
      " |    |-- ArXiv: string (nullable = true)\n",
      " |    |-- CorpusId: string (nullable = true)\n",
      " |    |-- DBLP: string (nullable = true)\n",
      " |    |-- DOI: string (nullable = true)\n",
      " |    |-- MAG: string (nullable = true)\n",
      " |    |-- PubMed: string (nullable = true)\n",
      " |    |-- PubMedCentral: string (nullable = true)\n",
      " |-- fieldsOfStudy: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- publicationtypes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- publicationdate: string (nullable = true)\n",
      " |-- journalName: string (nullable = true)\n",
      " |-- journalPages: string (nullable = true)\n",
      " |-- journalVolume: string (nullable = true)\n",
      " |-- venue: string (nullable = true)\n",
      " |-- publicationvenueid: string (nullable = true)\n",
      " |-- isopenaccess: boolean (nullable = true)\n",
      " |-- referencecount: integer (nullable = true)\n",
      " |-- citationcount: integer (nullable = true)\n",
      " |-- influentialcitationcount: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------\n",
      " id                       | 80809568                                                                                                     \n",
      " title                    | The essentials of identity â€“ differentiating normal from pathological                                        \n",
      " S2Url                    | https://www.semanticscholar.org/paper/6d35ab3955b1beb231a276d3fec0914fe903d71a                               \n",
      " year                     | 2012                                                                                                         \n",
      " doi                      | 10.1016/J.NEURENF.2012.05.027                                                                                \n",
      " pmid                     | null                                                                                                         \n",
      " magId                    | 2332503270                                                                                                   \n",
      " externalids              | {null, null, 80809568, null, 10.1016/J.NEURENF.2012.05.027, 2332503270, null, null}                          \n",
      " fieldsOfStudy            | [Philosophy, Psychology]                                                                                     \n",
      " publicationtypes         | null                                                                                                         \n",
      " publicationdate          | 2012-07-01                                                                                                   \n",
      " journalName              |                                                                                                              \n",
      " journalPages             | null                                                                                                         \n",
      " journalVolume            |                                                                                                              \n",
      " venue                    |                                                                                                              \n",
      " publicationvenueid       | null                                                                                                         \n",
      " isopenaccess             | false                                                                                                        \n",
      " referencecount           | 0                                                                                                            \n",
      " citationcount            | 1                                                                                                            \n",
      " influentialcitationcount | 0                                                                                                            \n",
      "-RECORD 1--------------------------------------------------------------------------------------------------------------------------------\n",
      " id                       | 81441234                                                                                                     \n",
      " title                    | The Interferon-Induced Antiviral Protein MxA: Functional and Therapeutic Aspects Relating to Virus Infection \n",
      " S2Url                    | https://www.semanticscholar.org/paper/07e49eeb3a60db9b9e8f39ac98889b922aea441c                               \n",
      " year                     | 2009                                                                                                         \n",
      " doi                      | null                                                                                                         \n",
      " pmid                     | null                                                                                                         \n",
      " magId                    | 33193565                                                                                                     \n",
      " externalids              | {null, null, 81441234, null, null, 33193565, null, null}                                                     \n",
      " fieldsOfStudy            | [Medicine, Biology]                                                                                          \n",
      " publicationtypes         | null                                                                                                         \n",
      " publicationdate          | 2009-03-01                                                                                                   \n",
      " journalName              |                                                                                                              \n",
      " journalPages             | null                                                                                                         \n",
      " journalVolume            |                                                                                                              \n",
      " venue                    |                                                                                                              \n",
      " publicationvenueid       | null                                                                                                         \n",
      " isopenaccess             | false                                                                                                        \n",
      " referencecount           | 0                                                                                                            \n",
      " citationcount            | 0                                                                                                            \n",
      " influentialcitationcount | 0                                                                                                            \n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 13.5 ms, sys: 3.41 ms, total: 16.9 ms\n",
      "Wall time: 1.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This function will be used for extracting only the Semantic Scholar FOS in string format\n",
    "# Semantic Scholar uses several models, but we keep only FOS from s2-fos-model\n",
    "def extractFOS(x):\n",
    "    try:\n",
    "        return [el['category'] for el in x\n",
    "            if el['source'] == \"s2-fos-model\"]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "extractFOS_UDF = F.udf(extractFOS, ArrayType(StringType()))\n",
    "\n",
    "# Adapt columns names and formats for backwards compatibility\n",
    "dataset = df_papers.select(F.col('corpusid').alias('id'), \\\n",
    "                           'title', \\\n",
    "                           F.col('url').alias('S2Url'), \\\n",
    "                           F.col('year').cast(IntegerType()), \\\n",
    "                           F.col('externalids.DOI').alias('doi'), \\\n",
    "                           F.col('externalids.PubMed').alias('pmid'), \\\n",
    "                           F.col('externalids.MAG').alias('magId'), \\\n",
    "                           'externalids', \\\n",
    "                           extractFOS_UDF(F.col('s2fieldsofstudy')).alias(\"fieldsOfStudy\"), \\\n",
    "                           'publicationtypes', \\\n",
    "                           'publicationdate', \\\n",
    "                           F.col('journal.name').alias('journalName'), \\\n",
    "                           F.col('journal.pages').alias('journalPages'), \\\n",
    "                           F.col('journal.volume').alias('journalVolume'), \\\n",
    "                           'venue', \\\n",
    "                           'publicationvenueid', \\\n",
    "                           'isopenaccess', \\\n",
    "                           F.col('referencecount').cast(IntegerType()), \\\n",
    "                           F.col('citationcount').cast(IntegerType()), \\\n",
    "                           F.col('influentialcitationcount').cast(IntegerType()) \\\n",
    "                          )\n",
    "dataset.printSchema()\n",
    "dataset.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a822df-6309-4f24-a8aa-a0416b2a74b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts available: 105538378\n",
      "root\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- corpusid: long (nullable = true)\n",
      " |-- openaccessinfo: struct (nullable = true)\n",
      " |    |-- externalids: struct (nullable = true)\n",
      " |    |    |-- ACL: string (nullable = true)\n",
      " |    |    |-- ArXiv: string (nullable = true)\n",
      " |    |    |-- DOI: string (nullable = true)\n",
      " |    |    |-- MAG: string (nullable = true)\n",
      " |    |    |-- PubMedCentral: string (nullable = true)\n",
      " |    |-- license: string (nullable = true)\n",
      " |    |-- status: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------------------------------------\n",
      " abstract       | The invention discloses a preparing method of blonanserin intermediate. The method is processed according to the foll... \n",
      " corpusid       | 102720041                                                                                                                \n",
      " openaccessinfo | {{null, null, null, 2747728283, null}, null, null, null}                                                                 \n",
      "-RECORD 1----------------------------------------------------------------------------------------------------------------------------------\n",
      " abstract       | The gypsum salt bed is located deep in the Carboniferous system of Tarim Basin, and its temperature is 110-130 â„ƒ. Dur... \n",
      " corpusid       | 130918190                                                                                                                \n",
      " openaccessinfo | {{null, null, null, 2350583218, null}, null, null, null}                                                                 \n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 155 ms, sys: 10.3 ms, total: 165 ms\n",
      "Wall time: 7min 50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dir_abstracts = dir_data.joinpath('abstracts')\n",
    "df_abstracts = spark.read.json('file:///' + dir_abstracts.as_posix())\n",
    "\n",
    "#We drop corrupt records\n",
    "df_abstracts = df_abstracts.cache()\n",
    "df_abstracts = df_abstracts.where(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
    "\n",
    "print('Number of abstracts available:', df_abstracts.count())\n",
    "df_abstracts.printSchema()\n",
    "df_abstracts.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e98b70b-5d4c-461e-a33c-4d2fa5ed4272",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- paperAbstract: string (nullable = true)\n",
      " |-- openaccessinfo: struct (nullable = true)\n",
      " |    |-- externalids: struct (nullable = true)\n",
      " |    |    |-- ACL: string (nullable = true)\n",
      " |    |    |-- ArXiv: string (nullable = true)\n",
      " |    |    |-- DOI: string (nullable = true)\n",
      " |    |    |-- MAG: string (nullable = true)\n",
      " |    |    |-- PubMedCentral: string (nullable = true)\n",
      " |    |-- license: string (nullable = true)\n",
      " |    |-- status: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------------------------------------\n",
      " id             | 102720041                                                                                                                \n",
      " paperAbstract  | The invention discloses a preparing method of blonanserin intermediate. The method is processed according to the foll... \n",
      " openaccessinfo | {{null, null, null, 2747728283, null}, null, null, null}                                                                 \n",
      "-RECORD 1----------------------------------------------------------------------------------------------------------------------------------\n",
      " id             | 130918190                                                                                                                \n",
      " paperAbstract  | The gypsum salt bed is located deep in the Carboniferous system of Tarim Basin, and its temperature is 110-130 â„ƒ. Dur... \n",
      " openaccessinfo | {{null, null, null, 2350583218, null}, null, null, null}                                                                 \n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 3.34 ms, sys: 4.07 ms, total: 7.41 ms\n",
      "Wall time: 4.26 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Adapt columns names and formats for backwards compatibility\n",
    "df_abstracts = df_abstracts.select(F.col('corpusid').alias('id'), \\\n",
    "                           F.col('abstract').alias('paperAbstract'), \\\n",
    "                           'openaccessinfo' \\\n",
    "                          )\n",
    "df_abstracts.printSchema()\n",
    "df_abstracts.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cd51877-ccb4-4fea-a59a-2e9c9efa67e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m/opt/spark-3.4.0-bin-3.3.1/python/pyspark/sql/dataframe.py:2977\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   2945\u001b[0m \n\u001b[1;32m   2946\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2974\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[1;32m   2975\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 2977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2978\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   2979\u001b[0m     )\n\u001b[1;32m   2980\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'id'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 42 with no recent heartbeats: 309268 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 41 with no recent heartbeats: 313560 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 38 with no recent heartbeats: 312240 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 32 with no recent heartbeats: 312937 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 40 with no recent heartbeats: 312137 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 34 with no recent heartbeats: 313811 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 43 with no recent heartbeats: 318435 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 37 with no recent heartbeats: 315586 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 31 with no recent heartbeats: 316989 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 WARN HeartbeatReceiver: Removing executor 25 with no recent heartbeats: 311379 ms exceeds timeout 300000 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 42 on node74.cluster.tsc.uc3m.es: Executor heartbeat timed out after 309268 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 41 on node01.cluster.tsc.uc3m.es: Executor heartbeat timed out after 313560 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 38 on node87.cluster.tsc.uc3m.es: Executor heartbeat timed out after 312240 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 32 on node02.cluster.tsc.uc3m.es: Executor heartbeat timed out after 312937 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 40 on node13.cluster.tsc.uc3m.es: Executor heartbeat timed out after 312137 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 34 on node25.cluster.tsc.uc3m.es: Executor heartbeat timed out after 313811 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 43 on node50.cluster.tsc.uc3m.es: Executor heartbeat timed out after 318435 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 37 on node85.cluster.tsc.uc3m.es: Executor heartbeat timed out after 315586 ms\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 31 on node59.cluster.tsc.uc3m.es: Executor heartbeat timed out after 316989 ms\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_63 !\n",
      "24/10/13 05:00:56 ERROR TaskSchedulerImpl: Lost executor 25 on node47.cluster.tsc.uc3m.es: Executor heartbeat timed out after 311379 ms\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_93 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_178 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_143 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_176 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_28 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_53 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_54 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_62 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_94 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_137 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_38 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_177 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_101 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_139 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_144 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_102 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_18 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_8 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_175 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_188 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_36 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_25 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_127 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_11 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_133 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_21 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_65 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_4 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_15 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_70 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_47 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_31 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_68 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_59 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_123 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_168 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_208 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_20 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_129 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_173 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_130 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_1 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_184 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_72 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_70 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_123 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_74 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_73 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_24 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_35 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_28 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_130 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_177 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_128 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_162 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_5 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_190 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_174 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_14 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_12 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_110 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_52 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_194 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_27 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_148 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_153 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_161 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_30 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_98 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_145 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_45 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_107 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_23 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_3 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_114 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_101 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_42 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_58 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_198 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_86 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_17 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_13 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_65 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_66 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_101 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_97 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_193 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_37 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_156 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_192 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_110 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_181 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_189 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_113 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_149 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_2 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_44 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_159 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_143 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_95 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_119 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_7 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_43 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_140 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_103 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_10 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_41 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_84 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_0 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_56 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_100 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_20 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_136 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_158 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_67 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_6 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_4 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_190 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_0 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_201 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_37 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_33 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_17 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_146 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_186 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_53 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_66 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_4 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_14 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_206 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_55 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_97 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_157 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_99 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_111 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_187 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_148 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_90 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_121 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_84 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_26 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_49 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_17 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_99 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_39 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_163 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_51 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_149 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_155 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_19 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_25 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_153 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_187 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_162 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_7 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_17 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_7 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_110 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_95 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_34 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_126 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_166 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_27 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_79 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_164 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_89 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_156 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_192 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_23 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_9 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_135 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_24 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_3 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_27 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_48 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_74 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_183 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_135 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_91 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_64 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_44 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_170 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_193 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_40 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_83 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_43 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_3 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_152 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_150 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_87 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_18 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_55 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_3 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_147 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_160 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_144 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_111 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_60 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_33 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_8 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_113 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_106 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_150 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_8 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_142 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_111 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_1 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_102 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_180 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_46 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_5 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_191 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_23 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_18 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_183 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_64 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_66 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_109 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_41 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_185 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_88 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_7 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_105 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_157 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_28 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_60 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_68 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_146 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_38 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_181 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_112 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_28 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_85 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_137 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_195 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_47 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_13 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_158 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_160 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_43 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_36 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_112 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_22 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_2 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_80 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_12 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_25 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_71 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_122 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_49 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_205 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_113 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_195 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_12 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_128 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_17 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_22 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_15 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_159 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_78 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_114 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_167 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_46 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_2 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_120 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_180 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_176 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_179 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_77 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_87 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_9 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_82 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_134 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_72 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_51 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_39 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_121 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_124 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_19 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_194 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_117 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_50 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_157 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_120 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_200 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_115 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_32 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_124 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_39 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_197 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_31 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_197 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_89 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_85 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_31 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_23 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_164 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_131 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_59 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_44 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_86 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_79 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_29 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_196 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_172 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_171 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_88 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_140 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_209 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_90 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_108 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_46 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_76 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_49 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_2 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_40 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_161 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_135 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_77 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_48 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_141 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_12 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_142 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_57 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_207 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_73 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_119 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_92 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_118 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_91 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_22 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_115 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_166 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_169 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_32 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_141 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_10 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_161 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_32 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_53 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_0 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_155 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_67 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_105 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_117 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_114 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_34 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_116 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_204 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_138 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_55 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_160 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_175 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_165 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_184 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_30 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_98 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_42 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_156 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_20 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_69 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_108 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_33 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_13 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_75 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_26 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_11 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_21 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_154 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_74 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_139 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_203 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_50 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_158 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_150 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_18 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_1 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_23 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_71 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_37 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_122 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_47 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_189 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_109 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_171 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_78 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_79 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_72 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_10 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_151 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_162 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_202 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_3 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_112 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_38 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_81 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_174 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_51 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_131 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_175 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_173 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_98 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_129 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_165 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_40 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_186 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_45 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_83 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_24 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_6 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_14 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_136 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_4 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_56 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_125 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_130 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_187 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_178 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_45 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_22 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_199 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_169 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_118 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_47 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_134 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_96 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_129 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_191 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_122 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_163 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_29 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_24 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_168 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_30 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_56 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_132 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_199 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_78 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_172 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_67 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_167 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_119 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_35 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_174 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_42 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_14 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_120 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_36 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_26 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_81 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_82 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_104 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_138 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_76 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_16 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_80 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_210 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_34 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_9 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_100 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_94 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_63 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_19 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_75 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_165 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_133 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_168 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_41 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_142 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_30 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_68 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_18 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_75 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_34 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_6 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_29 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_69 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_60 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_65 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_61 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_26 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_145 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_211 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_46 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_87 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_5 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_147 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_71 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_48 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_151 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_49 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_8 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_64 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_143 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_15 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_127 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_190 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_181 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_127 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_39 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_125 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_125 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_182 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_58 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_97 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_197 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_2 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_134 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_38 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_153 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_32 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_106 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_155 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_24 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_182 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_132 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_185 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_41 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_19 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_9 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_103 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_54 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_16 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_180 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_56 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_25 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_186 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_196 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_173 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_194 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_96 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_179 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_104 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_20 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_124 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_77 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_16 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_57 !\n",
      "24/10/13 05:00:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_227_35 !\n",
      "Exception in thread \"Thread-5146\" java.io.IOException: Failed to connect to node38.cluster.tsc.uc3m.es/10.0.13.58:7337\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:284)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)\n",
      "\tat org.apache.spark.network.shuffle.mesos.MesosExternalBlockStoreClient.registerDriverWithShuffleService(MesosExternalBlockStoreClient.java:77)\n",
      "\tat org.apache.spark.scheduler.cluster.mesos.MesosCoarseGrainedSchedulerBackend.statusUpdate(MesosCoarseGrainedSchedulerBackend.scala:658)\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: node38.cluster.tsc.uc3m.es/10.0.13.58:7337\n",
      "Caused by: java.net.NoRouteToHostException: No route to host\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "I1013 05:01:09.796247  2574 sched.cpp:2208] Asked to abort the driver\n",
      "I1013 05:01:09.796372  2574 sched.cpp:1237] Aborting framework 9f0d2cd7-3d2e-4f84-9992-0191cb1e3672-0011\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from node74.cluster.tsc.uc3m.es/10.0.13.94:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from /10.0.13.94:48020\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from node92.cluster.tsc.uc3m.es/10.0.13.112:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from node36.cluster.tsc.uc3m.es/10.0.13.56:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from node76.cluster.tsc.uc3m.es/10.0.13.96:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from node25.cluster.tsc.uc3m.es/10.0.13.45:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from node50.cluster.tsc.uc3m.es/10.0.13.70:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from node24.cluster.tsc.uc3m.es/10.0.13.44:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:19 WARN TransportChannelHandler: Exception in connection from node02.cluster.tsc.uc3m.es/10.0.13.22:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:37 WARN TransportChannelHandler: Exception in connection from node77.cluster.tsc.uc3m.es/10.0.13.97:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:37 WARN TransportChannelHandler: Exception in connection from node34.cluster.tsc.uc3m.es/10.0.13.54:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:37 WARN TransportChannelHandler: Exception in connection from /10.0.13.70:50678\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:39 WARN TransportChannelHandler: Exception in connection from node12.cluster.tsc.uc3m.es/10.0.13.32:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:39 WARN TransportChannelHandler: Exception in connection from node18.cluster.tsc.uc3m.es/10.0.13.38:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:39 WARN TransportChannelHandler: Exception in connection from /10.0.13.79:56304\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:39 WARN TransportChannelHandler: Exception in connection from node59.cluster.tsc.uc3m.es/10.0.13.79:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:39 WARN TransportChannelHandler: Exception in connection from /10.0.13.105:54746\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:39 WARN TransportChannelHandler: Exception in connection from node70.cluster.tsc.uc3m.es/10.0.13.90:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:39 WARN TransportChannelHandler: Exception in connection from node89.cluster.tsc.uc3m.es/10.0.13.109:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:39 WARN TransportChannelHandler: Exception in connection from node13.cluster.tsc.uc3m.es/10.0.13.33:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:41 WARN TransportChannelHandler: Exception in connection from node85.cluster.tsc.uc3m.es/10.0.13.105:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:41 WARN TransportChannelHandler: Exception in connection from node81.cluster.tsc.uc3m.es/10.0.13.101:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:41 WARN TransportChannelHandler: Exception in connection from /10.0.13.21:38016\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:41 WARN TransportChannelHandler: Exception in connection from node83.cluster.tsc.uc3m.es/10.0.13.103:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:41 WARN TransportChannelHandler: Exception in connection from /10.0.13.45:34406\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:41 WARN TransportChannelHandler: Exception in connection from node71.cluster.tsc.uc3m.es/10.0.13.91:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:41 WARN TransportChannelHandler: Exception in connection from node28.cluster.tsc.uc3m.es/10.0.13.48:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from node05.cluster.tsc.uc3m.es/10.0.13.25:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from /10.0.13.107:56316\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from node60.cluster.tsc.uc3m.es/10.0.13.80:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from /10.0.13.67:52862\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from node67.cluster.tsc.uc3m.es/10.0.13.87:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from node87.cluster.tsc.uc3m.es/10.0.13.107:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from /10.0.13.33:52096\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from node79.cluster.tsc.uc3m.es/10.0.13.99:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/13 05:11:43 WARN TransportChannelHandler: Exception in connection from /10.0.13.22:39122\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = (dataset.join(df_abstracts, dataset.id ==  df_abstracts.id, \"left\")\n",
    "                      .drop(df_abstracts.id)\n",
    "                ).cache()\n",
    "\n",
    "print('Number of documents in dataset:', dataset.count())\n",
    "dataset.printSchema()\n",
    "dataset.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7ab2769-9ce1-4adc-bd9b-04dae52a75ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/12 01:23:07 WARN TaskSetManager: Lost task 101.0 in stage 17.0 (TID 680) (node05.cluster.tsc.uc3m.es executor 2): TaskKilled (Stage cancelled)\n",
      "24/10/12 01:23:07 WARN TaskSetManager: Lost task 83.2 in stage 17.0 (TID 678) (node05.cluster.tsc.uc3m.es executor 2): TaskKilled (Stage cancelled)\n",
      "24/10/12 01:23:07 WARN TaskSetManager: Lost task 89.1 in stage 17.0 (TID 688) (node05.cluster.tsc.uc3m.es executor 2): TaskKilled (Stage cancelled)\n",
      "24/10/12 01:23:07 WARN TaskSetManager: Lost task 104.0 in stage 17.0 (TID 683) (node05.cluster.tsc.uc3m.es executor 2): TaskKilled (Stage cancelled)\n",
      "24/10/12 01:27:04 ERROR TaskSchedulerImpl: Lost executor 2 on node05.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:27:04 WARN TaskSetManager: Lost task 29.0 in stage 22.0 (TID 822) (node05.cluster.tsc.uc3m.es executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:27:04 WARN TaskSetManager: Lost task 20.0 in stage 22.0 (TID 818) (node05.cluster.tsc.uc3m.es executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:27:04 WARN TaskSetManager: Lost task 11.0 in stage 22.0 (TID 814) (node05.cluster.tsc.uc3m.es executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:27:04 WARN TaskSetManager: Lost task 38.0 in stage 22.0 (TID 825) (node05.cluster.tsc.uc3m.es executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_29 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_3 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_65 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_38 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_29 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_66 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_11 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_50 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_19 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_43 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_9 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_33 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_13 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_45 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_57 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_39 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_23 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_74 !\n",
      "24/10/12 01:27:04 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_20 !\n",
      "24/10/12 01:28:40 ERROR TaskSchedulerImpl: Lost executor 10 on node33.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:28:40 WARN TaskSetManager: Lost task 42.0 in stage 22.0 (TID 869) (node33.cluster.tsc.uc3m.es executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:28:40 WARN TaskSetManager: Lost task 32.0 in stage 22.0 (TID 860) (node33.cluster.tsc.uc3m.es executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:28:40 WARN TaskSetManager: Lost task 36.0 in stage 22.0 (TID 865) (node33.cluster.tsc.uc3m.es executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:28:40 WARN TaskSetManager: Lost task 39.0 in stage 22.0 (TID 867) (node33.cluster.tsc.uc3m.es executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:28:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_51 !\n",
      "24/10/12 01:28:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_60 !\n",
      "24/10/12 01:28:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_41 !\n",
      "24/10/12 01:28:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_45 !\n",
      "24/10/12 01:30:32 ERROR TaskSchedulerImpl: Lost executor 4 on node77.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:30:32 WARN TaskSetManager: Lost task 73.0 in stage 22.0 (TID 893) (node77.cluster.tsc.uc3m.es executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:30:32 WARN TaskSetManager: Lost task 85.0 in stage 22.0 (TID 904) (node77.cluster.tsc.uc3m.es executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:30:32 WARN TaskSetManager: Lost task 81.0 in stage 22.0 (TID 901) (node77.cluster.tsc.uc3m.es executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:30:32 WARN TaskSetManager: Lost task 80.0 in stage 22.0 (TID 900) (node77.cluster.tsc.uc3m.es executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_67 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_40 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_22 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_7 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_12 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_84 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_22 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_2 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_40 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_61 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_25 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_16 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_12 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_2 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_62 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_37 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_47 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_55 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_32 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_32 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_54 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_34 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_46 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_50 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_48 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_49 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_44 !\n",
      "24/10/12 01:30:32 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_47_45 !\n",
      "24/10/12 01:32:07 ERROR TaskSchedulerImpl: Lost executor 16 on node37.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:32:07 WARN TaskSetManager: Lost task 97.0 in stage 22.0 (TID 920) (node37.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:32:07 WARN TaskSetManager: Lost task 99.0 in stage 22.0 (TID 922) (node37.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:32:07 WARN TaskSetManager: Lost task 98.0 in stage 22.0 (TID 921) (node37.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:32:07 WARN TaskSetManager: Lost task 101.0 in stage 22.0 (TID 924) (node37.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:32:07 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_14 !\n",
      "24/10/12 01:32:07 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_6 !\n",
      "24/10/12 01:32:07 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_50 !\n",
      "24/10/12 01:32:07 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_48 !\n",
      "24/10/12 01:32:07 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_49 !\n",
      "24/10/12 01:32:07 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_22 !\n",
      "24/10/12 01:32:07 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_30 !\n",
      "24/10/12 01:32:07 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_57 !\n",
      "24/10/12 01:36:56 WARN HeartbeatReceiver: Removing executor 15 with no recent heartbeats: 346237 ms exceeds timeout 300000 ms\n",
      "24/10/12 01:36:56 WARN HeartbeatReceiver: Removing executor 20 with no recent heartbeats: 340202 ms exceeds timeout 300000 ms\n",
      "24/10/12 01:36:56 ERROR TaskSchedulerImpl: Lost executor 15 on node06.cluster.tsc.uc3m.es: Executor heartbeat timed out after 346237 ms\n",
      "24/10/12 01:36:56 WARN TaskSetManager: Lost task 63.0 in stage 22.0 (TID 887) (node06.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 346237 ms\n",
      "24/10/12 01:36:56 WARN TaskSetManager: Lost task 59.0 in stage 22.0 (TID 886) (node06.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 346237 ms\n",
      "24/10/12 01:36:56 WARN TaskSetManager: Lost task 65.0 in stage 22.0 (TID 889) (node06.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 346237 ms\n",
      "24/10/12 01:36:56 WARN TaskSetManager: Lost task 64.0 in stage 22.0 (TID 888) (node06.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 346237 ms\n",
      "24/10/12 01:36:56 ERROR TaskSchedulerImpl: Lost executor 20 on node06.cluster.tsc.uc3m.es: Executor heartbeat timed out after 340202 ms\n",
      "24/10/12 01:36:56 WARN TaskSetManager: Lost task 91.0 in stage 22.0 (TID 914) (node06.cluster.tsc.uc3m.es executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 340202 ms\n",
      "24/10/12 01:36:56 WARN TaskSetManager: Lost task 90.0 in stage 22.0 (TID 913) (node06.cluster.tsc.uc3m.es executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 340202 ms\n",
      "24/10/12 01:36:56 WARN TaskSetManager: Lost task 93.0 in stage 22.0 (TID 916) (node06.cluster.tsc.uc3m.es executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 340202 ms\n",
      "24/10/12 01:36:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_1 !\n",
      "24/10/12 01:36:56 WARN TaskSetManager: Lost task 92.0 in stage 22.0 (TID 915) (node06.cluster.tsc.uc3m.es executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 340202 ms\n",
      "24/10/12 01:36:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_63 !\n",
      "24/10/12 01:36:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_65 !\n",
      "24/10/12 01:36:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_24 !\n",
      "24/10/12 01:36:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_59 !\n",
      "24/10/12 01:36:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_64 !\n",
      "24/10/12 01:36:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_17 !\n",
      "24/10/12 01:36:56 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_9 !\n",
      "24/10/12 01:37:00 WARN TransportChannelHandler: Exception in connection from /10.0.13.26:41710\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/12 01:37:26 ERROR TaskSchedulerImpl: Lost executor 17 on node67.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:37:26 WARN TaskSetManager: Lost task 64.1 in stage 22.0 (TID 1013) (node67.cluster.tsc.uc3m.es executor 17): ExecutorLostFailure (executor 17 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:37:26 WARN TaskSetManager: Lost task 59.1 in stage 22.0 (TID 1015) (node67.cluster.tsc.uc3m.es executor 17): ExecutorLostFailure (executor 17 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:37:26 WARN TaskSetManager: Lost task 91.1 in stage 22.0 (TID 1012) (node67.cluster.tsc.uc3m.es executor 17): ExecutorLostFailure (executor 17 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:37:26 WARN TaskSetManager: Lost task 65.1 in stage 22.0 (TID 1014) (node67.cluster.tsc.uc3m.es executor 17): ExecutorLostFailure (executor 17 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_160 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_101 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_13 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_139 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_161 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_112 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_132 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_5 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_131 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_94 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_74 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_55 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_122 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_53 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_104 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_150 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_168 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_21 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_28 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_79 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_133 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_162 !\n",
      "24/10/12 01:37:26 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_98 !\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 307 ms, sys: 59.4 ms, total: 367 ms\n",
      "Wall time: 17min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_abstracts = spark.read.json('file:///' + dir_abstracts.as_posix())\n",
    "\n",
    "\n",
    "dataset.write.parquet(\n",
    "    'file:///' + dir_parquet.joinpath(f\"papers.parquet\").as_posix(),\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1074d96e-94a5-4b31-9545-2c5237f59f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/12 01:40:35 ERROR TaskSchedulerImpl: Lost executor 11 on node92.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN TaskSetManager: Lost task 51.0 in stage 25.0 (TID 1205) (node92.cluster.tsc.uc3m.es executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN TaskSetManager: Lost task 40.0 in stage 25.0 (TID 1196) (node92.cluster.tsc.uc3m.es executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN TaskSetManager: Lost task 47.0 in stage 25.0 (TID 1201) (node92.cluster.tsc.uc3m.es executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN TaskSetManager: Lost task 25.0 in stage 25.0 (TID 1191) (node92.cluster.tsc.uc3m.es executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_153 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_35 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_69 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_71 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_155 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_87 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_193 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_95 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_56 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_121 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_128 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_130 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_159 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_192 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_186 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_31 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_120 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_3 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_33 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_105 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_169 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_64 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_140 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_70 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_43 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_89 !\n",
      "24/10/12 01:40:35 ERROR TaskSchedulerImpl: Lost executor 12 on node60.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN TaskSetManager: Lost task 17.0 in stage 25.0 (TID 1187) (node60.cluster.tsc.uc3m.es executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN TaskSetManager: Lost task 22.0 in stage 25.0 (TID 1189) (node60.cluster.tsc.uc3m.es executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN TaskSetManager: Lost task 21.0 in stage 25.0 (TID 1188) (node60.cluster.tsc.uc3m.es executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN TaskSetManager: Lost task 55.0 in stage 25.0 (TID 1208) (node60.cluster.tsc.uc3m.es executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_187 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_65 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_137 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_152 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_110 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_12 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_111 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_76 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_171 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_90 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_164 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_93 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_27 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_78 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_181 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_109 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_126 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_103 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_4 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_134 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_176 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_167 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_142 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_19 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_75 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_138 !\n",
      "24/10/12 01:40:35 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_77 !\n",
      "24/10/12 01:40:37 ERROR TaskSchedulerImpl: Lost executor 18 on node36.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:37 WARN TaskSetManager: Lost task 28.0 in stage 25.0 (TID 1192) (node36.cluster.tsc.uc3m.es executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:37 WARN TaskSetManager: Lost task 53.0 in stage 25.0 (TID 1206) (node36.cluster.tsc.uc3m.es executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:37 WARN TaskSetManager: Lost task 41.0 in stage 25.0 (TID 1197) (node36.cluster.tsc.uc3m.es executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:37 WARN TaskSetManager: Lost task 48.0 in stage 25.0 (TID 1202) (node36.cluster.tsc.uc3m.es executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_199 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_174 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_91 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_38 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_29 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_157 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_166 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_113 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_11 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_143 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_198 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_85 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_154 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_80 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_156 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_114 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_81 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_178 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_73 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_179 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_92 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_123 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_20 !\n",
      "24/10/12 01:40:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_124 !\n",
      "24/10/12 01:40:39 ERROR TaskSchedulerImpl: Lost executor 19 on node28.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:39 WARN TaskSetManager: Lost task 54.0 in stage 25.0 (TID 1207) (node28.cluster.tsc.uc3m.es executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:39 WARN TaskSetManager: Lost task 49.0 in stage 25.0 (TID 1203) (node28.cluster.tsc.uc3m.es executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:39 WARN TaskSetManager: Lost task 34.0 in stage 25.0 (TID 1194) (node28.cluster.tsc.uc3m.es executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:39 WARN TaskSetManager: Lost task 45.0 in stage 25.0 (TID 1199) (node28.cluster.tsc.uc3m.es executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_36 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_97 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_32 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_146 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_147 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_194 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_197 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_42 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_145 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_39 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_106 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_99 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_165 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_59 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_185 !\n",
      "24/10/12 01:40:39 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_115 !\n",
      "24/10/12 01:40:40 ERROR TaskSchedulerImpl: Lost executor 13 on node59.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN TaskSetManager: Lost task 51.1 in stage 25.0 (TID 1219) (node59.cluster.tsc.uc3m.es executor 13): ExecutorLostFailure (executor 13 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN TaskSetManager: Lost task 60.0 in stage 25.0 (TID 1221) (node59.cluster.tsc.uc3m.es executor 13): ExecutorLostFailure (executor 13 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN TaskSetManager: Lost task 47.1 in stage 25.0 (TID 1217) (node59.cluster.tsc.uc3m.es executor 13): ExecutorLostFailure (executor 13 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN TaskSetManager: Lost task 57.0 in stage 25.0 (TID 1220) (node59.cluster.tsc.uc3m.es executor 13): ExecutorLostFailure (executor 13 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_151 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_158 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_183 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_175 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_2 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_100 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_66 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_149 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_163 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_172 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_182 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_82 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_184 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_26 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_52 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_108 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_102 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_127 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_136 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_10 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_180 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_107 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_72 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_129 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_63 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_135 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_68 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_18 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_177 !\n",
      "24/10/12 01:40:40 ERROR TaskSchedulerImpl: Lost executor 14 on node28.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN TaskSetManager: Lost task 37.0 in stage 25.0 (TID 1195) (node28.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN TaskSetManager: Lost task 50.0 in stage 25.0 (TID 1204) (node28.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN TaskSetManager: Lost task 46.0 in stage 25.0 (TID 1200) (node28.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN TaskSetManager: Lost task 24.0 in stage 25.0 (TID 1190) (node28.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_173 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_86 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_196 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_8 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_23 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_83 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_125 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_58 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_141 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_148 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_15 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_195 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_88 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_170 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_96 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_0 !\n",
      "24/10/12 01:40:40 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_144 !\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers with PMID: 37497271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/12 01:43:57 ERROR TaskSchedulerImpl: Lost executor 23 on node36.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:43:57 WARN TaskSetManager: Lost task 66.0 in stage 32.0 (TID 1357) (node36.cluster.tsc.uc3m.es executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:43:57 WARN TaskSetManager: Lost task 3.0 in stage 32.0 (TID 1327) (node36.cluster.tsc.uc3m.es executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:43:57 WARN TaskSetManager: Lost task 39.0 in stage 32.0 (TID 1347) (node36.cluster.tsc.uc3m.es executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:43:57 WARN TaskSetManager: Lost task 23.0 in stage 32.0 (TID 1337) (node36.cluster.tsc.uc3m.es executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_190 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_161 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_40 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_189 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_61 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_188 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_25 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_191 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_53 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_150 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_62 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_44 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_30 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_17 !\n",
      "24/10/12 01:43:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_162 !\n",
      "24/10/12 01:44:15 ERROR TaskSchedulerImpl: Lost executor 22 on node83.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:44:15 WARN TaskSetManager: Lost task 63.0 in stage 32.0 (TID 1354) (node83.cluster.tsc.uc3m.es executor 22): ExecutorLostFailure (executor 22 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:44:15 WARN TaskSetManager: Lost task 35.0 in stage 32.0 (TID 1344) (node83.cluster.tsc.uc3m.es executor 22): ExecutorLostFailure (executor 22 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:44:15 WARN TaskSetManager: Lost task 18.0 in stage 32.0 (TID 1334) (node83.cluster.tsc.uc3m.es executor 22): ExecutorLostFailure (executor 22 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:44:15 WARN TaskSetManager: Lost task 75.0 in stage 32.0 (TID 1364) (node83.cluster.tsc.uc3m.es executor 22): ExecutorLostFailure (executor 22 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:44:15 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_67 !\n",
      "24/10/12 01:44:15 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_74 !\n",
      "24/10/12 01:44:15 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_16 !\n",
      "24/10/12 01:44:15 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_13 !\n",
      "24/10/12 01:44:15 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_7 !\n",
      "24/10/12 01:44:15 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_5 !\n",
      "24/10/12 01:44:15 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_79 !\n",
      "24/10/12 01:44:15 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_98 !\n",
      "24/10/12 01:45:24 ERROR TaskSchedulerImpl: Lost executor 28 on node71.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:24 WARN TaskSetManager: Lost task 78.0 in stage 32.0 (TID 1375) (node71.cluster.tsc.uc3m.es executor 28): ExecutorLostFailure (executor 28 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:24 WARN TaskSetManager: Lost task 89.0 in stage 32.0 (TID 1384) (node71.cluster.tsc.uc3m.es executor 28): ExecutorLostFailure (executor 28 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:24 WARN TaskSetManager: Lost task 85.0 in stage 32.0 (TID 1380) (node71.cluster.tsc.uc3m.es executor 28): ExecutorLostFailure (executor 28 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:24 WARN TaskSetManager: Lost task 91.0 in stage 32.0 (TID 1386) (node71.cluster.tsc.uc3m.es executor 28): ExecutorLostFailure (executor 28 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_51 !\n",
      "24/10/12 01:45:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_72 !\n",
      "24/10/12 01:45:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_12 !\n",
      "24/10/12 01:45:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_60 !\n",
      "24/10/12 01:45:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_32 !\n",
      "24/10/12 01:45:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_57 !\n",
      "24/10/12 01:45:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_47 !\n",
      "24/10/12 01:45:24 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_58 !\n",
      "24/10/12 01:45:30 ERROR TaskSchedulerImpl: Lost executor 27 on node83.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:30 WARN TaskSetManager: Lost task 96.0 in stage 32.0 (TID 1390) (node83.cluster.tsc.uc3m.es executor 27): ExecutorLostFailure (executor 27 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:30 WARN TaskSetManager: Lost task 42.0 in stage 32.0 (TID 1348) (node83.cluster.tsc.uc3m.es executor 27): ExecutorLostFailure (executor 27 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:30 WARN TaskSetManager: Lost task 91.1 in stage 32.0 (TID 1392) (node83.cluster.tsc.uc3m.es executor 27): ExecutorLostFailure (executor 27 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:30 WARN TaskSetManager: Lost task 93.0 in stage 32.0 (TID 1388) (node83.cluster.tsc.uc3m.es executor 27): ExecutorLostFailure (executor 27 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:45:30 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_26 !\n",
      "24/10/12 01:45:30 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_4 !\n",
      "24/10/12 01:45:30 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_50 !\n",
      "24/10/12 01:45:30 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_24 !\n",
      "24/10/12 01:45:30 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_46 !\n",
      "24/10/12 01:45:30 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_37 !\n",
      "24/10/12 01:45:30 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_68 !\n",
      "24/10/12 01:45:30 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_42 !\n",
      "24/10/12 01:46:45 ERROR TaskSchedulerImpl: Lost executor 26 on node59.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:46:45 WARN TaskSetManager: Lost task 145.0 in stage 32.0 (TID 1434) (node59.cluster.tsc.uc3m.es executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:46:45 WARN TaskSetManager: Lost task 144.0 in stage 32.0 (TID 1433) (node59.cluster.tsc.uc3m.es executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:46:45 WARN TaskSetManager: Lost task 137.0 in stage 32.0 (TID 1427) (node59.cluster.tsc.uc3m.es executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:46:45 WARN TaskSetManager: Lost task 136.0 in stage 32.0 (TID 1426) (node59.cluster.tsc.uc3m.es executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_101 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_93 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_36 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_112 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_122 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_104 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_92 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_0 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_64 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_19 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_95 !\n",
      "24/10/12 01:46:45 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_89 !\n",
      "24/10/12 01:47:16 WARN TransportChannelHandler: Exception in connection from /10.0.13.25:40402\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/12 01:47:16 ERROR TransportResponseHandler: Still have 2 requests outstanding when connection from /10.0.13.25:40402 is closed\n",
      "24/10/12 01:47:16 ERROR TaskSchedulerImpl: Lost executor 21 on node05.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:47:16 WARN TaskSetManager: Lost task 96.1 in stage 32.0 (TID 1398) (node05.cluster.tsc.uc3m.es executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:47:16 WARN TaskSetManager: Lost task 149.0 in stage 32.0 (TID 1442) (node05.cluster.tsc.uc3m.es executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:47:16 WARN TaskSetManager: Lost task 152.0 in stage 32.0 (TID 1444) (node05.cluster.tsc.uc3m.es executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:47:16 WARN TaskSetManager: Lost task 146.0 in stage 32.0 (TID 1435) (node05.cluster.tsc.uc3m.es executor 21): ExecutorLostFailure (executor 21 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: Error trying to remove shuffle 5 from block manager BlockManagerId(21, node05.cluster.tsc.uc3m.es, 35063, None)\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: Error trying to remove broadcast 24 from block manager BlockManagerId(21, node05.cluster.tsc.uc3m.es, 35063, None)\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_14 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_160 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_119 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_6 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_34 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_97 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_78 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_117 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_84 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for broadcast_24_piece0 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_31 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_118 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_9 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_94 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_71 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_1 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_11 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_116 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_168 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_85 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_56 !\n",
      "24/10/12 01:47:16 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_45 !\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers with DOI: 125038998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/12 01:49:57 ERROR TaskSchedulerImpl: Lost executor 33 on node92.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:49:57 WARN TaskSetManager: Lost task 32.0 in stage 39.0 (TID 1582) (node92.cluster.tsc.uc3m.es executor 33): ExecutorLostFailure (executor 33 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:49:57 WARN TaskSetManager: Lost task 19.0 in stage 39.0 (TID 1576) (node92.cluster.tsc.uc3m.es executor 33): ExecutorLostFailure (executor 33 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:49:57 WARN TaskSetManager: Lost task 37.0 in stage 39.0 (TID 1585) (node92.cluster.tsc.uc3m.es executor 33): ExecutorLostFailure (executor 33 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:49:57 WARN TaskSetManager: Lost task 26.0 in stage 39.0 (TID 1579) (node92.cluster.tsc.uc3m.es executor 33): ExecutorLostFailure (executor 33 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_147 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_136 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_145 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_172 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_106 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_105 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_103 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_107 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_176 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_170 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_144 !\n",
      "24/10/12 01:49:57 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_177 !\n",
      "24/10/12 01:50:28 ERROR TaskSchedulerImpl: Lost executor 24 on node22.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:28 WARN TaskSetManager: Lost task 37.1 in stage 39.0 (TID 1623) (node22.cluster.tsc.uc3m.es executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:28 WARN TaskSetManager: Lost task 44.0 in stage 39.0 (TID 1626) (node22.cluster.tsc.uc3m.es executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:28 WARN TaskSetManager: Lost task 32.1 in stage 39.0 (TID 1625) (node22.cluster.tsc.uc3m.es executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:28 WARN TaskSetManager: Lost task 45.0 in stage 39.0 (TID 1627) (node22.cluster.tsc.uc3m.es executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_90 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_151 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_108 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_83 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_33 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_73 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_166 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_141 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_169 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_179 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_148 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_55 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_15 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_88 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_167 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_59 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_123 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_22 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_21 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_82 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_28 !\n",
      "24/10/12 01:50:28 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_140 !\n",
      "24/10/12 01:50:37 ERROR TaskSchedulerImpl: Lost executor 29 on node24.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:37 WARN TaskSetManager: Lost task 37.2 in stage 39.0 (TID 1638) (node24.cluster.tsc.uc3m.es executor 29): ExecutorLostFailure (executor 29 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:37 WARN TaskSetManager: Lost task 47.0 in stage 39.0 (TID 1640) (node24.cluster.tsc.uc3m.es executor 29): ExecutorLostFailure (executor 29 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:37 WARN TaskSetManager: Lost task 32.2 in stage 39.0 (TID 1636) (node24.cluster.tsc.uc3m.es executor 29): ExecutorLostFailure (executor 29 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:37 WARN TaskSetManager: Lost task 46.0 in stage 39.0 (TID 1639) (node24.cluster.tsc.uc3m.es executor 29): ExecutorLostFailure (executor 29 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_100 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_86 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_137 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_132 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_146 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_29 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_131 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_152 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_193 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_198 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_76 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_128 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_171 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_52 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_139 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_154 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_80 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_192 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_109 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_81 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_126 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_10 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_178 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_133 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_70 !\n",
      "24/10/12 01:50:37 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_138 !\n",
      "24/10/12 01:50:55 ERROR TaskSchedulerImpl: Lost executor 35 on node60.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:55 WARN TaskSetManager: Lost task 64.0 in stage 39.0 (TID 1656) (node60.cluster.tsc.uc3m.es executor 35): ExecutorLostFailure (executor 35 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:55 WARN TaskSetManager: Lost task 71.0 in stage 39.0 (TID 1660) (node60.cluster.tsc.uc3m.es executor 35): ExecutorLostFailure (executor 35 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:55 WARN TaskSetManager: Lost task 57.0 in stage 39.0 (TID 1651) (node60.cluster.tsc.uc3m.es executor 35): ExecutorLostFailure (executor 35 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:55 WARN TaskSetManager: Lost task 46.1 in stage 39.0 (TID 1642) (node60.cluster.tsc.uc3m.es executor 35): ExecutorLostFailure (executor 35 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:50:55 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_14 !\n",
      "24/10/12 01:50:55 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_1 !\n",
      "24/10/12 01:50:55 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_6 !\n",
      "24/10/12 01:50:55 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_11 !\n",
      "24/10/12 01:50:55 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_96 !\n",
      "24/10/12 01:50:55 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_149 !\n",
      "24/10/12 01:50:55 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_163 !\n",
      "24/10/12 01:50:55 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_159 !\n",
      "24/10/12 01:51:43 ERROR TaskSchedulerImpl: Lost executor 36 on node79.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:51:43 WARN TaskSetManager: Lost task 116.0 in stage 39.0 (TID 1691) (node79.cluster.tsc.uc3m.es executor 36): ExecutorLostFailure (executor 36 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:51:43 WARN TaskSetManager: Lost task 150.0 in stage 39.0 (TID 1696) (node79.cluster.tsc.uc3m.es executor 36): ExecutorLostFailure (executor 36 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:51:43 WARN TaskSetManager: Lost task 78.0 in stage 39.0 (TID 1672) (node79.cluster.tsc.uc3m.es executor 36): ExecutorLostFailure (executor 36 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:51:43 WARN TaskSetManager: Lost task 112.0 in stage 39.0 (TID 1690) (node79.cluster.tsc.uc3m.es executor 36): ExecutorLostFailure (executor 36 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_183 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_13 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_5 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_9 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_58 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_60 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_53 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_182 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_184 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_0 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_185 !\n",
      "24/10/12 01:51:43 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_45 !\n",
      "24/10/12 01:52:58 WARN TransportChannelHandler: Exception in connection from node06.cluster.tsc.uc3m.es/10.0.13.26:7337\n",
      "java.io.IOException: No route to host\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:259)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "[Stage 48:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique DOIs: 123595615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Papers with PMID:\", dataset.where(F.col(\"pmid\").isNotNull()).count())\n",
    "print(\"Papers with DOI:\", dataset.where(F.col(\"doi\").isNotNull()).count())\n",
    "print(\"Unique DOIs:\", dataset.where(F.col(\"doi\").isNotNull()).select('doi').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db005cf-bb20-4135-9762-1a112e1d2288",
   "metadata": {},
   "source": [
    "### 4.2. Table **`authors`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f64f74-bb6b-4070-a306-e0c5ee2fa78b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors available: 98089208\n",
      "root\n",
      " |-- affiliations: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- aliases: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- authorid: string (nullable = true)\n",
      " |-- citationcount: long (nullable = true)\n",
      " |-- externalids: struct (nullable = true)\n",
      " |    |-- DBLP: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- ORCID: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- hindex: long (nullable = true)\n",
      " |-- homepage: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- papercount: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n",
      "-RECORD 0----------------------------------------------------------\n",
      " affiliations  | null                                              \n",
      " aliases       | [S A Shohaib]                                     \n",
      " authorid      | 2244420168                                        \n",
      " citationcount | 0                                                 \n",
      " externalids   | null                                              \n",
      " hindex        | 0                                                 \n",
      " homepage      | null                                              \n",
      " name          | S. A. Shohaib                                     \n",
      " papercount    | 1                                                 \n",
      " url           | https://www.semanticscholar.org/author/2244420168 \n",
      "-RECORD 1----------------------------------------------------------\n",
      " affiliations  | null                                              \n",
      " aliases       | null                                              \n",
      " authorid      | 2093767694                                        \n",
      " citationcount | 2                                                 \n",
      " externalids   | null                                              \n",
      " hindex        | 1                                                 \n",
      " homepage      | null                                              \n",
      " name          | Wolfgang Dipl.-Ing. SchÃ¤rfl                       \n",
      " papercount    | 4                                                 \n",
      " url           | https://www.semanticscholar.org/author/2093767694 \n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 51.5 ms, sys: 814 Î¼s, total: 52.3 ms\n",
      "Wall time: 1min 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dir_authors = dir_data.joinpath('authors')\n",
    "df_authors = spark.read.json('file:///' + dir_authors.as_posix())\n",
    "\n",
    "#We drop corrupt records\n",
    "df_authors = df_authors.cache()\n",
    "df_authors = df_authors.where(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
    "\n",
    "print('Number of authors available:', df_authors.count())\n",
    "df_authors.printSchema()\n",
    "df_authors.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17229fe0-9993-4d13-af48-66bbdd60e57a",
   "metadata": {},
   "source": [
    "<span style=\"background-color:yellow;\">Right now, it seems affiliations are missing, and ORCID also missing for most of the authors (<0.35%)? We will continue checking to see if this becomes any better.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed28d5d1-31c8-4fd3-9b2b-51e21d6b0972",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------\n",
      " affiliations  | null                                                                                \n",
      " aliases       | [J. Arenas-garcia, Jeronimo Arenas-garcia, JerÃ³nimo Arenas-garcÃ­a]                  \n",
      " authorid      | 1385756446                                                                          \n",
      " citationcount | 3028                                                                                \n",
      " externalids   | {[JerÃ³nimo Arenas-GarcÃ­a], null}                                                    \n",
      " hindex        | 29                                                                                  \n",
      " homepage      | null                                                                                \n",
      " name          | J. Arenas-GarcÃ­a                                                                    \n",
      " papercount    | 104                                                                                 \n",
      " url           | https://www.semanticscholar.org/author/1385756446                                   \n",
      "-RECORD 1--------------------------------------------------------------------------------------------\n",
      " affiliations  | null                                                                                \n",
      " aliases       | [J Arenas-garcÃ­a, J. Arenas-garcia, Jeronimo Arenas-garcia, JerÃ³nimo Arenas-garcÃ­a] \n",
      " authorid      | 1750044                                                                             \n",
      " citationcount | 5                                                                                   \n",
      " externalids   | null                                                                                \n",
      " hindex        | 1                                                                                   \n",
      " homepage      | null                                                                                \n",
      " name          | J. Arenas-GarcÃ­a                                                                    \n",
      " papercount    | 1                                                                                   \n",
      " url           | https://www.semanticscholar.org/author/1750044                                      \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Search for rows where the name column contains \"John\"\n",
    "search_term = \"J. Arenas-GarcÃ­a\"\n",
    "result = df_authors.filter(F.col(\"name\").like(f\"%{search_term}%\"))\n",
    "\n",
    "result.show(truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c526c93-f961-45cb-ae14-315d333a3b98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors with affiliations: 247494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 61:===================================>                   (20 + 11) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors with ORCID: 35387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Number of authors with affiliations:\", df_authors.where(F.col(\"affiliations\").isNotNull()).count())\n",
    "print(\"Number of authors with ORCID:\", df_authors.where(F.col(\"externalids.ORCID\").isNotNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f93435d5-f404-4920-a66e-c0cd7a9dbce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- aliases: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- papercount: integer (nullable = true)\n",
      " |-- citationcount: integer (nullable = true)\n",
      " |-- hindex: integer (nullable = true)\n",
      "\n",
      "-RECORD 0------------------------------------\n",
      " id            | 2244420168                  \n",
      " name          | S. A. Shohaib               \n",
      " aliases       | [S A Shohaib]               \n",
      " papercount    | 1                           \n",
      " citationcount | 0                           \n",
      " hindex        | 0                           \n",
      "-RECORD 1------------------------------------\n",
      " id            | 2093767694                  \n",
      " name          | Wolfgang Dipl.-Ing. SchÃ¤rfl \n",
      " aliases       | null                        \n",
      " papercount    | 4                           \n",
      " citationcount | 2                           \n",
      " hindex        | 1                           \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adapt columns names and formats for backwards compatibility\n",
    "df_authors = df_authors.select(F.col('authorid').alias('id'), \\\n",
    "                               \"name\", \\\n",
    "                               \"aliases\", \\\n",
    "                               F.col('papercount').cast(IntegerType()), \\\n",
    "                               F.col('citationcount').cast(IntegerType()), \\\n",
    "                               F.col('hindex').cast(IntegerType()) \\\n",
    "                              )\n",
    "df_authors.printSchema()\n",
    "df_authors.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ddb863f-822b-4905-8d89-a2509af185ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:==================================================>     (28 + 3) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 ms, sys: 529 Î¼s, total: 21.3 ms\n",
      "Wall time: 27 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_authors.write.parquet(\n",
    "    'file:///' + dir_parquet.joinpath(f\"authors.parquet\").as_posix(),\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be360e76-5daa-4199-95c1-78b8740a82f3",
   "metadata": {},
   "source": [
    "### 4.3. Table **`paper_author`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb2a721-e981-4dc3-8081-fc44bdd5b0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paper_author entries: 625447465\n",
      "root\n",
      " |-- paper_id: long (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      "\n",
      "-RECORD 0-------------\n",
      " paper_id  | 7487231  \n",
      " author_id | 10000172 \n",
      "-RECORD 1-------------\n",
      " paper_id  | 21187561 \n",
      " author_id | 10000172 \n",
      "only showing top 2 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_paper_author = df_papers.select(F.col('corpusid').alias('paper_id'), F.explode('authors'))\n",
    "df_paper_author = df_paper_author.select('paper_id', F.col('col.authorId').alias('author_id'))\n",
    "\n",
    "#We make sure that authors are in the author table\n",
    "df_author_aux = df_authors.select(\"id\")\n",
    "df_paper_author = (\n",
    "    df_paper_author.join(df_author_aux, \\\n",
    "                      df_paper_author.author_id ==  df_author_aux.id, \"left\")\n",
    "                    .drop(df_author_aux.id)\n",
    ").cache()\n",
    "\n",
    "print(\"Number of paper_author entries:\", df_paper_author.count())\n",
    "df_paper_author.printSchema()\n",
    "print(df_paper_author.show(n=2, vertical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "531e9309-6fba-43f4-8c07-2bc00e340e18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/12 02:04:14 ERROR TaskSchedulerImpl: Lost executor 30 on node05.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:04:14 WARN TaskSetManager: Lost task 137.0 in stage 78.0 (TID 2414) (node05.cluster.tsc.uc3m.es executor 30): ExecutorLostFailure (executor 30 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:04:14 WARN TaskSetManager: Lost task 143.0 in stage 78.0 (TID 2417) (node05.cluster.tsc.uc3m.es executor 30): ExecutorLostFailure (executor 30 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:04:14 WARN TaskSetManager: Lost task 155.0 in stage 78.0 (TID 2420) (node05.cluster.tsc.uc3m.es executor 30): ExecutorLostFailure (executor 30 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:04:14 WARN TaskSetManager: Lost task 113.0 in stage 78.0 (TID 2411) (node05.cluster.tsc.uc3m.es executor 30): ExecutorLostFailure (executor 30 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_91 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_154 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_121 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_19 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_69 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_42 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_61 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_25 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_12 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_48 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_54 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_50 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_170 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_52 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_164 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_15 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_11 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_44 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_1 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_43 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_7 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_196 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_152 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_54 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_16 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_35 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_104 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_116 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_62 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_198 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_27 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_93 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_27 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_102 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_8 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_107 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_57 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_126 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_58 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_4 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_99 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_21 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_5 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_31 !\n",
      "24/10/12 02:04:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_11 !\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save dataframe as parquet\n",
    "df_paper_author.write.parquet(\n",
    "    'file:///' + dir_parquet.joinpath(\"paper_author.parquet\").as_posix(),\n",
    "    mode=\"overwrite\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cc802-0d1f-4bdb-a24a-a1ccad0ff727",
   "metadata": {},
   "source": [
    "### 4.4. Table **`citations`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddf9066f-9121-4bef-a27d-36374132c2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/12 02:10:14 ERROR TaskSchedulerImpl: Lost executor 39 on node18.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:10:14 WARN TaskSetManager: Lost task 53.0 in stage 80.0 (TID 2715) (node18.cluster.tsc.uc3m.es executor 39): ExecutorLostFailure (executor 39 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:10:14 WARN TaskSetManager: Lost task 55.0 in stage 80.0 (TID 2717) (node18.cluster.tsc.uc3m.es executor 39): ExecutorLostFailure (executor 39 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:10:14 WARN TaskSetManager: Lost task 58.0 in stage 80.0 (TID 2720) (node18.cluster.tsc.uc3m.es executor 39): ExecutorLostFailure (executor 39 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:10:14 WARN TaskSetManager: Lost task 57.0 in stage 80.0 (TID 2719) (node18.cluster.tsc.uc3m.es executor 39): ExecutorLostFailure (executor 39 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_92 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_37 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_117 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_10 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_84 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_199 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_116 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_188 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_36 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_93 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_50 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_195 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_20 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_118 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_85 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_63 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_189 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_21 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_0 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_6 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_61 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_52 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_13 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_57 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_115 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_26 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_95 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_59 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_188 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_191 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_92 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_137_30 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_29 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_16 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_62 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_51 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_199_94 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_86_89 !\n",
      "24/10/12 02:10:14 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_10_40 !\n",
      "24/10/12 02:38:31 WARN TaskSetManager: Lost task 207.0 in stage 81.0 (TID 3085) (node50.cluster.tsc.uc3m.es executor 43): com.esotericsoftware.kryo.KryoException: java.io.IOException: No space left on device\n",
      "Serialization trace:\n",
      "buffers (org.apache.spark.sql.execution.columnar.DefaultCachedBatch)\n",
      "\tat com.esotericsoftware.kryo.io.Output.flush(Output.java:188)\n",
      "\tat com.esotericsoftware.kryo.io.Output.require(Output.java:164)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:251)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:237)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:49)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:38)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:332)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:86)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:274)\n",
      "\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n",
      "\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1544)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1542)\n",
      "\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1542)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1462)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1526)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:101)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: No space left on device\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.write0(Native Method)\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:62)\n",
      "\tat java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:113)\n",
      "\tat java.base/sun.nio.ch.IOUtil.write(IOUtil.java:79)\n",
      "\tat java.base/sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:280)\n",
      "\tat org.apache.spark.storage.CountingWritableChannel.write(DiskStore.scala:353)\n",
      "\tat java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)\n",
      "\tat java.base/java.nio.channels.Channels.writeFully(Channels.java:97)\n",
      "\tat java.base/java.nio.channels.Channels$1.write(Channels.java:172)\n",
      "\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:123)\n",
      "\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:225)\n",
      "\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:178)\n",
      "\tat com.esotericsoftware.kryo.io.Output.flush(Output.java:185)\n",
      "\t... 50 more\n",
      "\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of citations: 2663282456\n",
      "root\n",
      " |-- source: long (nullable = true)\n",
      " |-- dest: long (nullable = true)\n",
      " |-- isinfluential: boolean (nullable = true)\n",
      "\n",
      "-RECORD 0-----------------\n",
      " source        | 30717035 \n",
      " dest          | 19447476 \n",
      " isinfluential | false    \n",
      "-RECORD 1-----------------\n",
      " source        | 41671791 \n",
      " dest          | 30145272 \n",
      " isinfluential | false    \n",
      "only showing top 2 rows\n",
      "\n",
      "CPU times: user 592 ms, sys: 48.4 ms, total: 640 ms\n",
      "Wall time: 36min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "dir_citations = dir_data.joinpath('citations')\n",
    "df_citations = spark.read.json('file:///' + dir_citations.as_posix())\n",
    "\n",
    "#We drop corrupt records\n",
    "df_citations = df_citations.cache()\n",
    "df_citations = df_citations.where(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
    "\n",
    "#Select and rename some columns\n",
    "#We skip the context (text surronding the citation) and intention (result, background, methods),\n",
    "#since these data are most likely not going to be used in IntelComp\n",
    "\n",
    "df_citations = df_citations.select(F.col('citingcorpusid').alias('source'), \\\n",
    "                                   F.col('citedcorpusid').alias('dest'), \\\n",
    "                                   'isinfluential')\n",
    "\n",
    "print('Number of citations:', df_citations.count())\n",
    "df_citations.printSchema()\n",
    "df_citations.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f00f6947-57ae-4f1e-9bd6-24119b4b14a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/12 02:47:14 WARN TaskSetManager: Lost task 192.0 in stage 85.0 (TID 3301) (node50.cluster.tsc.uc3m.es executor 43): java.io.FileNotFoundException: /export/workdir/spark/tmp/blockmgr-c1ea327c-21df-458b-81ef-40c2c345e281/0b/rdd_227_192 (No space left on device)\n",
      "\tat java.base/java.io.FileOutputStream.open0(Native Method)\n",
      "\tat java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)\n",
      "\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)\n",
      "\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:187)\n",
      "\tat org.apache.spark.storage.DiskStore.openForWrite(DiskStore.scala:156)\n",
      "\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:84)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1542)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1462)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1526)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "24/10/12 02:47:37 WARN TaskSetManager: Lost task 206.0 in stage 85.0 (TID 3302) (node50.cluster.tsc.uc3m.es executor 43): java.io.FileNotFoundException: /export/workdir/spark/tmp/blockmgr-c1ea327c-21df-458b-81ef-40c2c345e281/1d/rdd_227_206 (No space left on device)\n",
      "\tat java.base/java.io.FileOutputStream.open0(Native Method)\n",
      "\tat java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)\n",
      "\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)\n",
      "\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:187)\n",
      "\tat org.apache.spark.storage.DiskStore.openForWrite(DiskStore.scala:156)\n",
      "\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:84)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1542)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1462)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1526)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "24/10/12 02:48:19 WARN TaskSetManager: Lost task 208.0 in stage 85.0 (TID 3303) (node50.cluster.tsc.uc3m.es executor 43): java.io.FileNotFoundException: /export/workdir/spark/tmp/blockmgr-c1ea327c-21df-458b-81ef-40c2c345e281/1b/rdd_227_208 (No space left on device)\n",
      "\tat java.base/java.io.FileOutputStream.open0(Native Method)\n",
      "\tat java.base/java.io.FileOutputStream.open(FileOutputStream.java:298)\n",
      "\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237)\n",
      "\tat java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:187)\n",
      "\tat org.apache.spark.storage.DiskStore.openForWrite(DiskStore.scala:156)\n",
      "\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:84)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1542)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1462)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1526)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "24/10/12 02:48:19 WARN TaskSetManager: Lost task 182.0 in stage 85.0 (TID 3300) (node50.cluster.tsc.uc3m.es executor 43): com.esotericsoftware.kryo.KryoException: java.io.IOException: No space left on device\n",
      "Serialization trace:\n",
      "buffers (org.apache.spark.sql.execution.columnar.DefaultCachedBatch)\n",
      "\tat com.esotericsoftware.kryo.io.Output.flush(Output.java:188)\n",
      "\tat com.esotericsoftware.kryo.io.Output.require(Output.java:164)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:251)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:237)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:49)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:38)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:332)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:86)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:274)\n",
      "\tat org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:140)\n",
      "\tat org.apache.spark.serializer.SerializerManager.dataSerializeStream(SerializerManager.scala:177)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3(BlockManager.scala:1544)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$3$adapted(BlockManager.scala:1542)\n",
      "\tat org.apache.spark.storage.DiskStore.put(DiskStore.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1542)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1462)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1526)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1349)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:375)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:326)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:364)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:328)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: No space left on device\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.write0(Native Method)\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:62)\n",
      "\tat java.base/sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:113)\n",
      "\tat java.base/sun.nio.ch.IOUtil.write(IOUtil.java:79)\n",
      "\tat java.base/sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:280)\n",
      "\tat org.apache.spark.storage.CountingWritableChannel.write(DiskStore.scala:353)\n",
      "\tat java.base/java.nio.channels.Channels.writeFullyImpl(Channels.java:74)\n",
      "\tat java.base/java.nio.channels.Channels.writeFully(Channels.java:97)\n",
      "\tat java.base/java.nio.channels.Channels$1.write(Channels.java:172)\n",
      "\tat java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:123)\n",
      "\tat net.jpountz.lz4.LZ4BlockOutputStream.flushBufferedData(LZ4BlockOutputStream.java:225)\n",
      "\tat net.jpountz.lz4.LZ4BlockOutputStream.write(LZ4BlockOutputStream.java:178)\n",
      "\tat com.esotericsoftware.kryo.io.Output.flush(Output.java:185)\n",
      "\t... 48 more\n",
      "\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 198 ms, sys: 20.9 ms, total: 219 ms\n",
      "Wall time: 8min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Save dataframe as parquet\n",
    "df_citations.write.parquet(\n",
    "    'file:///' + dir_parquet.joinpath(\"citations.parquet\").as_posix(),\n",
    "    mode=\"overwrite\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3476ecd4-57ac-4c32-8f33-5e2350f445d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
