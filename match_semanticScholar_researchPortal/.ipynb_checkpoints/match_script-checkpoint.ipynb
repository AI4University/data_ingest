{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e420d98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                (0 + 31) / 31][Stage 1:>                 (0 + 1) / 31]\r"
     ]
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47791f9f",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e00d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                (1 + 30) / 31][Stage 1:>                 (0 + 2) / 31]\r"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import ArrayType, StringType, BooleanType, IntegerType\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, regexp_replace, when, coalesce, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fbb4ea",
   "metadata": {},
   "source": [
    "## 2. Define directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c0e75ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                (1 + 30) / 31][Stage 1:>                (0 + 10) / 31]\r"
     ]
    }
   ],
   "source": [
    "dir_data = Path('/export/data_ml4ds/AI4U/Datasets/semanticscholar/20231205/rawdata')\n",
    "dir_parquet_sematicscholar = Path('/export/data_ml4ds/AI4U/Datasets/semanticscholar/20231205/parquet')\n",
    "dir_parquet_researchportal = Path('/export/data_ml4ds/AI4U/Datasets/ResearchPortal/publications.parquet')\n",
    "dir_parquet_sematicscholar = Path('/export/data_ml4ds/AI4U/Datasets/semanticscholar/20231205/parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ddd7c-5f60-4f06-b41e-746c2b21eaed",
   "metadata": {},
   "source": [
    "## 1. Import tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e957624d-9793-4900-ba01-9397f58434d1",
   "metadata": {},
   "source": [
    "### 1.1. Table **`papers`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4989a1-4c1e-4570-b21b-30c841d8391c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 147 ms, sys: 36 ms, total: 183 ms\n",
      "Wall time: 9min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dir_papers = dir_data.joinpath('papers')\n",
    "df_papers = spark.read.json('file:///' + dir_papers.as_posix())\n",
    "\n",
    "#We drop corrupt records\n",
    "df_papers = df_papers.cache()\n",
    "df_papers = df_papers.where(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
    "\n",
    "#print('Number of papers available:', df_papers.count())\n",
    "#df_papers.printSchema()\n",
    "#df_papers.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3476ecd4-57ac-4c32-8f33-5e2350f445d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 73.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This function will be used for extracting only the Semantic Scholar FOS in string format\n",
    "# Semantic Scholar uses several models, but we keep only FOS from s2-fos-model\n",
    "def extractFOS(x):\n",
    "    try:\n",
    "        return [el['category'] for el in x\n",
    "            if el['source'] == \"s2-fos-model\"]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "extractFOS_UDF = F.udf(extractFOS, ArrayType(StringType()))\n",
    "\n",
    "# Adapt columns names and formats for backwards compatibility\n",
    "dataset = df_papers.select(F.col('corpusid').alias('id'), \\\n",
    "                           'title', \\\n",
    "                           F.col('url').alias('S2Url'), \\\n",
    "                           F.col('year').cast(IntegerType()), \\\n",
    "                           F.col('externalids.DOI').alias('doi'), \\\n",
    "                           F.col('externalids.PubMed').alias('pmid'), \\\n",
    "                           F.col('externalids.MAG').alias('magId'), \\\n",
    "                           'externalids', \\\n",
    "                           extractFOS_UDF(F.col('s2fieldsofstudy')).alias(\"fieldsOfStudy\"), \\\n",
    "                           'publicationtypes', \\\n",
    "                           'publicationdate', \\\n",
    "                           F.col('journal.name').alias('journalName'), \\\n",
    "                           F.col('journal.pages').alias('journalPages'), \\\n",
    "                           F.col('journal.volume').alias('journalVolume'), \\\n",
    "                           'venue', \\\n",
    "                           'publicationvenueid', \\\n",
    "                           'isopenaccess', \\\n",
    "                           F.col('referencecount').cast(IntegerType()), \\\n",
    "                           F.col('citationcount').cast(IntegerType()), \\\n",
    "                           F.col('influentialcitationcount').cast(IntegerType()) \\\n",
    "                          )\n",
    "#dataset.printSchema()\n",
    "#dataset.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff51e29f-8e50-48d2-a7fe-c9b85ebfb69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======================================================> (30 + 1) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63.6 ms, sys: 8.35 ms, total: 72 ms\n",
      "Wall time: 3min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dir_abstracts = dir_data.joinpath('abstracts')\n",
    "df_abstracts = spark.read.json('file:///' + dir_abstracts.as_posix())\n",
    "\n",
    "#We drop corrupt records\n",
    "df_abstracts = df_abstracts.cache()\n",
    "df_abstracts = df_abstracts.where(F.col(\"_corrupt_record\").isNull()).drop(\"_corrupt_record\")\n",
    "\n",
    "#print('Number of abstracts available:', df_abstracts.count())\n",
    "#df_abstracts.printSchema()\n",
    "#df_abstracts.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ea7b6bb-3f47-4d0d-90aa-c8b67cade00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.01 ms, sys: 0 ns, total: 2.01 ms\n",
      "Wall time: 11.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Adapt columns names and formats for backwards compatibility\n",
    "df_abstracts = df_abstracts.select(F.col('corpusid').alias('id'), \\\n",
    "                           F.col('abstract').alias('paperAbstract'), \\\n",
    "                           'openaccessinfo' \\\n",
    "                          )\n",
    "#df_abstracts.printSchema()\n",
    "#df_abstracts.show(n=2, truncate=120, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2337d6fa-0346-40a4-a819-ef22196e88b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.72 ms, sys: 272 Âµs, total: 2.99 ms\n",
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = (dataset.join(df_abstracts, dataset.id ==  df_abstracts.id, \"left\")\n",
    "                      .drop(df_abstracts.id)\n",
    "                ).cache()\n",
    "\n",
    "#print('Number of documents in dataset:', dataset.count())\n",
    "#dataset.printSchema()\n",
    "#dataset.show(n=2, truncate=120, vertical=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfbab9-40bf-40c6-9c53-ca2e1cb5291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Papers with PMID:\", dataset.where(F.col(\"pmid\").isNotNull()).count())\n",
    "print(\"Papers with DOI:\", dataset.where(F.col(\"doi\").isNotNull()).count())\n",
    "print(\"Unique DOIs:\", dataset.where(F.col(\"doi\").isNotNull()).select('doi').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffa24af8-48d5-46be-a2e4-aa5234d76311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- paperAbstract: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.select('id', 'title', 'doi', 'paperAbstract')\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48d1ca3-0903-4d64-821d-903ff593461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of publications in total in the Semantic Scholar database\n",
    "print('Number of documents in Semantic Scholar:', dataset.count())\n",
    "\n",
    "# Remove publications without Abstarct\n",
    "dataset_no_na = dataset.filter(~(col(\"paperAbstract\").isNull() | (col(\"paperAbstract\") == '')))\n",
    "print('Number of documents in Semantic Scholar: with abstract:', dataset_no_na.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a8588-d187-4af0-8c6c-a3f742592172",
   "metadata": {},
   "source": [
    "### 1.2. Table **`publications`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d265cd4-ad6e-468f-9e25-31d4e99de949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_publications = spark.read.parquet(str(Path(dir_parquet_researchportal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b0d12-dc9c-4ebf-97c4-87a16cc36980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_publications.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522779d9-b676-4f97-b0c6-6d390bf68ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                (0 + 28) / 31][Stage 1:>                 (0 + 0) / 31]\r"
     ]
    }
   ],
   "source": [
    "# Any duplicated? - NO\n",
    "duplicates_df_publications = df_publications.groupBy(\"actID\").count().filter(col(\"count\") > 1)\n",
    "print('Number of duplicated publications:', duplicates_df_publications.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c55939b-c621-45a8-9965-f59997f3dd99",
   "metadata": {},
   "source": [
    "## 2. Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "510d7dd0-2168-4b5f-963c-123cb804110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of publications in the Research Portal before the matching: 40244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:============================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of publications in the Research Portal without abstract before the matching: 24725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print number of publications in total in the Research Portal database\n",
    "print('Number of publications in the Research Portal before the matching:', df_publications.count())\n",
    "\n",
    "# Remove publications which already have Abstarct\n",
    "df_publications_na = df_publications.filter(\"Abstract IS NULL OR Abstract = ''\")\n",
    "print('Number of publications in the Research Portal without abstract before the matching:', df_publications_na.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96565652-e108-454c-afcb-339c3612f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the format of the DOI of publications in research portal match the format of Sematic Scholar\n",
    "doi_pattern = \"https://doi.org/\"\n",
    "# df_publications_na = df_publications_na.withColumn(\"clear_DOI\", regexp_replace(col(\"DOI\"), doi_pattern, \"\"))\n",
    "df_publications_na = df_publications_na.withColumn(\"doi_pub\", regexp_replace(col(\"DOI\"), doi_pattern, \"\"))\n",
    "df_publications_na = df_publications_na.withColumnRenamed(\"Title\", \"title_pub\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d10894-3050-4f7e-8cf0-cfc209961547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_publications_na.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb960ad9-ec6e-4a74-8aca-ec556942e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_no_na = dataset_no_na.withColumnRenamed(\"title\", \"title_ss\")\n",
    "dataset_no_na = dataset_no_na.withColumnRenamed(\"doi\", \"doi_ss\")\n",
    "#dataset_no_na.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b9255df-209a-4b32-86b7-c631b2482d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/24 09:59:12 ERROR scheduler.TaskSchedulerImpl: Lost executor 3 on node34.cluster.tsc.uc3m.es: Executor finished with state FAILED\n",
      "24/01/24 09:59:12 WARN server.TransportChannelHandler: Exception in connection from /10.0.13.54:33438\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat java.base/sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:356)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:253)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:350)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:719)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "24/01/24 09:59:12 WARN scheduler.TaskSetManager: Lost task 26.0 in stage 14.0 (TID 227) (node34.cluster.tsc.uc3m.es executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Executor finished with state FAILED\n",
      "24/01/24 09:59:12 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 14.0 (TID 217) (node34.cluster.tsc.uc3m.es executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Executor finished with state FAILED\n",
      "24/01/24 09:59:12 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 14.0 (TID 207) (node34.cluster.tsc.uc3m.es executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Executor finished with state FAILED\n",
      "24/01/24 09:59:12 WARN scheduler.TaskSetManager: Lost task 36.0 in stage 14.0 (TID 237) (node34.cluster.tsc.uc3m.es executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Executor finished with state FAILED\n",
      "24/01/24 09:59:12 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_8 !\n",
      "24/01/24 09:59:12 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_21 !\n",
      "24/01/24 09:59:12 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_20 !\n",
      "24/01/24 09:59:12 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_11 !\n",
      "24/01/24 09:59:12 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_10 !\n",
      "24/01/24 09:59:12 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_15 !\n",
      "24/01/24 09:59:12 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_1 !\n",
      "24/01/24 09:59:24 ERROR scheduler.TaskSchedulerImpl: Lost executor 4 on node77.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 09:59:24 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 14.0 (TID 202) (node77.cluster.tsc.uc3m.es executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 09:59:24 WARN scheduler.TaskSetManager: Lost task 31.0 in stage 14.0 (TID 232) (node77.cluster.tsc.uc3m.es executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 09:59:24 WARN scheduler.TaskSetManager: Lost task 21.0 in stage 14.0 (TID 222) (node77.cluster.tsc.uc3m.es executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 09:59:24 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 14.0 (TID 212) (node77.cluster.tsc.uc3m.es executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 09:59:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_17 !\n",
      "24/01/24 09:59:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_6 !\n",
      "24/01/24 09:59:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_16 !\n",
      "24/01/24 09:59:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_21 !\n",
      "24/01/24 09:59:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_5 !\n",
      "24/01/24 09:59:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_26 !\n",
      "24/01/24 09:59:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_13 !\n",
      "24/01/24 10:02:33 ERROR scheduler.TaskSchedulerImpl: Lost executor 7 on node37.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:33 WARN scheduler.TaskSetManager: Lost task 92.0 in stage 14.0 (TID 301) (node37.cluster.tsc.uc3m.es executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:33 WARN scheduler.TaskSetManager: Lost task 79.0 in stage 14.0 (TID 288) (node37.cluster.tsc.uc3m.es executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:33 WARN scheduler.TaskSetManager: Lost task 81.0 in stage 14.0 (TID 290) (node37.cluster.tsc.uc3m.es executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:33 WARN scheduler.TaskSetManager: Lost task 78.0 in stage 14.0 (TID 287) (node37.cluster.tsc.uc3m.es executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_18 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_45 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_10 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_7 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_20 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_27 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_46 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_24 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_23 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_30 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_47 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_0 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_64 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_37 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_9 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_17 !\n",
      "24/01/24 10:02:33 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_21 !\n",
      "24/01/24 10:02:43 ERROR scheduler.TaskSchedulerImpl: Lost executor 2 on node15.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:43 WARN scheduler.TaskSetManager: Lost task 104.0 in stage 14.0 (TID 313) (node15.cluster.tsc.uc3m.es executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:43 WARN scheduler.TaskSetManager: Lost task 83.0 in stage 14.0 (TID 292) (node15.cluster.tsc.uc3m.es executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:43 WARN scheduler.TaskSetManager: Lost task 97.0 in stage 14.0 (TID 306) (node15.cluster.tsc.uc3m.es executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:43 WARN scheduler.TaskSetManager: Lost task 96.0 in stage 14.0 (TID 305) (node15.cluster.tsc.uc3m.es executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_1 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_34 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_12 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_60 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_22 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_24 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_2 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_29 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_4 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_56 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_25 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_14 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_63 !\n",
      "24/01/24 10:02:43 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_62 !\n",
      "24/01/24 10:04:07 ERROR scheduler.TaskSchedulerImpl: Lost executor 1 on node02.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:07 WARN scheduler.TaskSetManager: Lost task 132.0 in stage 14.0 (TID 349) (node02.cluster.tsc.uc3m.es executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:07 WARN scheduler.TaskSetManager: Lost task 120.0 in stage 14.0 (TID 337) (node02.cluster.tsc.uc3m.es executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:07 WARN scheduler.TaskSetManager: Lost task 106.0 in stage 14.0 (TID 315) (node02.cluster.tsc.uc3m.es executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:07 WARN scheduler.TaskSetManager: Lost task 130.0 in stage 14.0 (TID 347) (node02.cluster.tsc.uc3m.es executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_89 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_27 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_35 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_88 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_15 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_5 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_4 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_25 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_17 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_75 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_7 !\n",
      "24/01/24 10:04:07 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_91 !\n",
      "24/01/24 10:04:09 ERROR scheduler.TaskSchedulerImpl: Lost executor 6 on node24.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:09 WARN scheduler.TaskSetManager: Lost task 123.0 in stage 14.0 (TID 340) (node24.cluster.tsc.uc3m.es executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:09 WARN scheduler.TaskSetManager: Lost task 119.0 in stage 14.0 (TID 336) (node24.cluster.tsc.uc3m.es executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:09 WARN scheduler.TaskSetManager: Lost task 140.0 in stage 14.0 (TID 357) (node24.cluster.tsc.uc3m.es executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:09 WARN scheduler.TaskSetManager: Lost task 124.0 in stage 14.0 (TID 341) (node24.cluster.tsc.uc3m.es executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_61 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_15 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_39 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_57 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_103 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_9 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_49 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_48 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_82 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_79 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_0 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_29 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_102 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_25 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_95 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_19 !\n",
      "24/01/24 10:04:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_5 !\n",
      "24/01/24 10:05:49 ERROR scheduler.TaskSchedulerImpl: Lost executor 0 on node20.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:05:49 WARN scheduler.TaskSetManager: Lost task 157.0 in stage 14.0 (TID 382) (node20.cluster.tsc.uc3m.es executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:05:49 WARN scheduler.TaskSetManager: Lost task 160.0 in stage 14.0 (TID 385) (node20.cluster.tsc.uc3m.es executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:05:49 WARN scheduler.TaskSetManager: Lost task 153.0 in stage 14.0 (TID 378) (node20.cluster.tsc.uc3m.es executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:05:49 WARN scheduler.TaskSetManager: Lost task 155.0 in stage 14.0 (TID 380) (node20.cluster.tsc.uc3m.es executor 0): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_10 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_40 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_77 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_101 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_114 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_135 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_3 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_13 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_26 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_70 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_125 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_2 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_20 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_131 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_30 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_0 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_23 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_44 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_132 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_112 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_121 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_73 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_96 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_41 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_80 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_74 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_28 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_11 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_11 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_65 !\n",
      "24/01/24 10:05:49 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_81 !\n",
      "24/01/24 10:06:06 ERROR scheduler.TaskSchedulerImpl: Lost executor 8 on node03.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:06 WARN scheduler.TaskSetManager: Lost task 157.1 in stage 14.0 (TID 400) (node03.cluster.tsc.uc3m.es executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:06 WARN scheduler.TaskSetManager: Lost task 169.0 in stage 14.0 (TID 394) (node03.cluster.tsc.uc3m.es executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:06 WARN scheduler.TaskSetManager: Lost task 171.0 in stage 14.0 (TID 396) (node03.cluster.tsc.uc3m.es executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:06 WARN scheduler.TaskSetManager: Lost task 153.1 in stage 14.0 (TID 398) (node03.cluster.tsc.uc3m.es executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_141 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_14 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_118 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_12 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_93 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_24 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_116 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_16 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_7 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_19 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_22 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_66 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_100 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_123 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_139 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_67 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_69 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_32 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_4 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_133 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_12 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_72 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_115 !\n",
      "24/01/24 10:06:06 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_2 !\n",
      "24/01/24 10:06:13 ERROR scheduler.TaskSchedulerImpl: Lost executor 12 on node81.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:13 WARN scheduler.TaskSetManager: Lost task 166.0 in stage 14.0 (TID 391) (node81.cluster.tsc.uc3m.es executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:13 WARN scheduler.TaskSetManager: Lost task 160.1 in stage 14.0 (TID 399) (node81.cluster.tsc.uc3m.es executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:13 WARN scheduler.TaskSetManager: Lost task 159.0 in stage 14.0 (TID 384) (node81.cluster.tsc.uc3m.es executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:13 WARN scheduler.TaskSetManager: Lost task 172.0 in stage 14.0 (TID 401) (node81.cluster.tsc.uc3m.es executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:13 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_138 !\n",
      "24/01/24 10:06:13 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_97 !\n",
      "24/01/24 10:06:13 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_83 !\n",
      "24/01/24 10:06:13 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_124 !\n",
      "24/01/24 10:06:13 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_78 !\n",
      "24/01/24 10:06:13 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_140 !\n",
      "24/01/24 10:06:13 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_130 !\n",
      "24/01/24 10:06:13 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_104 !\n",
      "24/01/24 10:06:24 ERROR scheduler.TaskSchedulerImpl: Lost executor 9 on node35.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:24 WARN scheduler.TaskSetManager: Lost task 159.1 in stage 14.0 (TID 403) (node35.cluster.tsc.uc3m.es executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:24 WARN scheduler.TaskSetManager: Lost task 106.1 in stage 14.0 (TID 363) (node35.cluster.tsc.uc3m.es executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:24 WARN scheduler.TaskSetManager: Lost task 172.1 in stage 14.0 (TID 402) (node35.cluster.tsc.uc3m.es executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:24 WARN scheduler.TaskSetManager: Lost task 160.2 in stage 14.0 (TID 404) (node35.cluster.tsc.uc3m.es executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_26 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_23 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_43 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_8 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_42 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_22 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_117 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_3 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_106 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_16 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_136 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_27 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_13 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_111 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_76 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_28 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_94 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_122 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_68 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_6 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_14 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_18 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_113 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_71 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_33 !\n",
      "24/01/24 10:06:24 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_120 !\n",
      "24/01/24 10:08:01 ERROR scheduler.TaskSchedulerImpl: Lost executor 5 on node74.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:08:01 WARN scheduler.TaskSetManager: Lost task 155.1 in stage 14.0 (TID 397) (node74.cluster.tsc.uc3m.es executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:08:01 WARN scheduler.TaskSetManager: Lost task 168.0 in stage 14.0 (TID 393) (node74.cluster.tsc.uc3m.es executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_29 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_30 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_39_3 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_50 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_58 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_134 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_92 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_18 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_167 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_119 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_99 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_59 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_51 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_28 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_137 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_90 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_8 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_19 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_38 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_53_9 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_98 !\n",
      "24/01/24 10:08:01 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_105 !\n",
      "[Stage 14:=====================================================>(199 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# perform a join of both tables in order of getting the number of matched publications\n",
    "joined_df = df_publications_na.join(\n",
    "    dataset_no_na,\n",
    "    (df_publications_na.doi_pub == dataset_no_na.doi_ss) & (df_publications_na.title_pub == dataset_no_na.title_ss),\n",
    "    \"inner\"\n",
    ")\n",
    "print('Number of matches:', joined_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22848d3e-5764-42f6-afb8-54194043c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a259bde-f85a-46e3-880b-d25fd100e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df_0 = joined_df.select('actID', 'id', 'title_pub', 'title_ss', 'doi_pub', 'doi_ss', 'paperAbstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b71d1dda-44f3-4332-be0d-e310f31c204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unir las DataFrames en funciÃ³n de la columna actID\n",
    "merged_df = df_publications.join(joined_df_0, \"actID\", \"left_outer\")\n",
    "\n",
    "# Actualizar el valor de Abstract con el valor de paperAbstract donde estÃ© disponible\n",
    "result_df = merged_df.withColumn(\"Abstract\", coalesce(col(\"paperAbstract\"), col(\"Abstract\")))\n",
    "\n",
    "# Seleccionar las columnas necesarias\n",
    "result_df = result_df.select(\"actID\", \"ActivityType\", \"Title\", \"Abstract\", \"Keywords\", \"Research_Areas\",\n",
    "                             \"DOI\", \"Year\", \"Publisher\", \"ISSN\", \"EISSN\", \"ISBN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c3675e4-1ce4-4e54-88fe-8c477df928b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/24 10:09:35 ERROR scheduler.TaskSchedulerImpl: Lost executor 14 on node69.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:09:35 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 23.0 (TID 501) (node69.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:09:35 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 23.0 (TID 512) (node69.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:09:35 WARN scheduler.TaskSetManager: Lost task 19.0 in stage 23.0 (TID 515) (node69.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:09:35 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 23.0 (TID 502) (node69.cluster.tsc.uc3m.es executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:09:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_199 !\n",
      "24/01/24 10:09:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_155 !\n",
      "24/01/24 10:09:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_149 !\n",
      "24/01/24 10:09:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_151 !\n",
      "24/01/24 10:09:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_148 !\n",
      "24/01/24 10:09:35 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_150 !\n",
      "24/01/24 10:10:17 ERROR scheduler.TaskSchedulerImpl: Lost executor 13 on node15.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:10:17 WARN scheduler.TaskSetManager: Lost task 47.0 in stage 23.0 (TID 577) (node15.cluster.tsc.uc3m.es executor 13): ExecutorLostFailure (executor 13 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:10:17 WARN scheduler.TaskSetManager: Lost task 49.0 in stage 23.0 (TID 579) (node15.cluster.tsc.uc3m.es executor 13): ExecutorLostFailure (executor 13 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:10:17 WARN scheduler.TaskSetManager: Lost task 16.1 in stage 23.0 (TID 561) (node15.cluster.tsc.uc3m.es executor 13): ExecutorLostFailure (executor 13 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:10:17 WARN scheduler.TaskSetManager: Lost task 50.0 in stage 23.0 (TID 580) (node15.cluster.tsc.uc3m.es executor 13): ExecutorLostFailure (executor 13 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_177 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_169 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_156 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_129 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_158 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_34 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_126 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_127 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_128 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_166 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_32 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_163 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_153 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_188 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_189 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_33 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_162 !\n",
      "24/01/24 10:10:17 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_30 !\n",
      "24/01/24 10:11:21 ERROR scheduler.TaskSchedulerImpl: Lost executor 18 on node50.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:21 WARN scheduler.TaskSetManager: Lost task 63.0 in stage 23.0 (TID 593) (node50.cluster.tsc.uc3m.es executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:21 WARN scheduler.TaskSetManager: Lost task 65.0 in stage 23.0 (TID 595) (node50.cluster.tsc.uc3m.es executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:21 WARN scheduler.TaskSetManager: Lost task 47.1 in stage 23.0 (TID 586) (node50.cluster.tsc.uc3m.es executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:21 WARN scheduler.TaskSetManager: Lost task 59.0 in stage 23.0 (TID 589) (node50.cluster.tsc.uc3m.es executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:21 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_182 !\n",
      "24/01/24 10:11:21 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_8 !\n",
      "24/01/24 10:11:21 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_181 !\n",
      "24/01/24 10:11:21 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_9 !\n",
      "24/01/24 10:11:21 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_7 !\n",
      "24/01/24 10:11:21 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_5 !\n",
      "24/01/24 10:11:21 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_180 !\n",
      "24/01/24 10:11:21 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_179 !\n",
      "24/01/24 10:11:59 ERROR scheduler.TaskSchedulerImpl: Lost executor 16 on node14.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:59 WARN scheduler.TaskSetManager: Lost task 97.0 in stage 23.0 (TID 627) (node14.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:59 WARN scheduler.TaskSetManager: Lost task 88.0 in stage 23.0 (TID 618) (node14.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:59 WARN scheduler.TaskSetManager: Lost task 47.2 in stage 23.0 (TID 615) (node14.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:59 WARN scheduler.TaskSetManager: Lost task 93.0 in stage 23.0 (TID 623) (node14.cluster.tsc.uc3m.es executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_23 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_196 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_39 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_106 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_83 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_160 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_49 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_46 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_24 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_56 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_22 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_195 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_198 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_78 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_159 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_197 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_21 !\n",
      "24/01/24 10:11:59 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_172 !\n",
      "24/01/24 10:12:09 ERROR scheduler.TaskSchedulerImpl: Lost executor 10 on node03.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:09 WARN scheduler.TaskSetManager: Lost task 111.0 in stage 23.0 (TID 636) (node03.cluster.tsc.uc3m.es executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:09 WARN scheduler.TaskSetManager: Lost task 96.0 in stage 23.0 (TID 626) (node03.cluster.tsc.uc3m.es executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:09 WARN scheduler.TaskSetManager: Lost task 88.1 in stage 23.0 (TID 640) (node03.cluster.tsc.uc3m.es executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:09 WARN scheduler.TaskSetManager: Lost task 77.0 in stage 23.0 (TID 607) (node03.cluster.tsc.uc3m.es executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_190 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_107 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_170 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_161 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_109 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_31 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_66 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_108 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_178 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_171 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_69 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_1 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_35 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_154 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_51 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_187 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_157 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_37 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_36 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_11 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_152 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_6 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_110 !\n",
      "24/01/24 10:12:09 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_38 !\n",
      "24/01/24 10:12:26 ERROR scheduler.TaskSchedulerImpl: Lost executor 15 on node36.cluster.tsc.uc3m.es: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:26 WARN scheduler.TaskSetManager: Lost task 77.1 in stage 23.0 (TID 648) (node36.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:26 WARN scheduler.TaskSetManager: Lost task 92.0 in stage 23.0 (TID 622) (node36.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:26 WARN scheduler.TaskSetManager: Lost task 104.0 in stage 23.0 (TID 634) (node36.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:26 WARN scheduler.TaskSetManager: Lost task 98.0 in stage 23.0 (TID 628) (node36.cluster.tsc.uc3m.es executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_61 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_145 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_194 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_67 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_60 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_193 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_20 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_144 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_18 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_65 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_17 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_12 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_146 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_62 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_191 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_143 !\n",
      "24/01/24 10:12:26 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_64_192 !\n",
      "24/01/24 10:13:23 WARN scheduler.TaskSetManager: Lost task 121.0 in stage 23.0 (TID 658) (node00.cluster.tsc.uc3m.es executor 24): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=121, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "24/01/24 10:13:23 WARN scheduler.TaskSetManager: Lost task 119.0 in stage 23.0 (TID 656) (node00.cluster.tsc.uc3m.es executor 24): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=119, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Failed to connect to node02.cluster.tsc.uc3m.es/10.0.13.22:7337\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: node02.cluster.tsc.uc3m.es/10.0.13.22:7337\n",
      "Caused by: java.net.NoRouteToHostException: No route to host\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      ")\n",
      "24/01/24 10:13:23 WARN scheduler.TaskSetManager: Lost task 120.0 in stage 23.0 (TID 657) (node00.cluster.tsc.uc3m.es executor 24): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=120, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "24/01/24 10:13:23 WARN scheduler.TaskSetManager: Lost task 77.2 in stage 23.0 (TID 655) (node00.cluster.tsc.uc3m.es executor 24): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=77, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "24/01/24 10:13:24 WARN scheduler.TaskSetManager: Lost task 124.0 in stage 23.0 (TID 661) (node50.cluster.tsc.uc3m.es executor 25): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=124, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "24/01/24 10:13:24 WARN scheduler.TaskSetManager: Lost task 125.0 in stage 23.0 (TID 662) (node50.cluster.tsc.uc3m.es executor 25): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=125, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "24/01/24 10:13:24 WARN scheduler.TaskSetManager: Lost task 130.0 in stage 23.0 (TID 663) (node50.cluster.tsc.uc3m.es executor 25): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=130, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "24/01/24 10:13:24 WARN scheduler.TaskSetManager: Lost task 123.0 in stage 23.0 (TID 660) (node50.cluster.tsc.uc3m.es executor 25): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=123, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Failed to connect to node02.cluster.tsc.uc3m.es/10.0.13.22:7337\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: node02.cluster.tsc.uc3m.es/10.0.13.22:7337\n",
      "Caused by: java.net.NoRouteToHostException: No route to host\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      ")\n",
      "24/01/24 10:13:38 WARN scheduler.TaskSetManager: Lost task 137.0 in stage 23.0 (TID 670) (node33.cluster.tsc.uc3m.es executor 26): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=137, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "24/01/24 10:13:38 WARN scheduler.TaskSetManager: Lost task 134.0 in stage 23.0 (TID 667) (node33.cluster.tsc.uc3m.es executor 26): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=134, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "24/01/24 10:13:38 WARN scheduler.TaskSetManager: Lost task 135.0 in stage 23.0 (TID 668) (node33.cluster.tsc.uc3m.es executor 26): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=135, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Failed to connect to node02.cluster.tsc.uc3m.es/10.0.13.22:7337\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:288)\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:218)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "Caused by: io.netty.channel.AbstractChannel$AnnotatedNoRouteToHostException: No route to host: node02.cluster.tsc.uc3m.es/10.0.13.22:7337\n",
      "Caused by: java.net.NoRouteToHostException: No route to host\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:330)\n",
      "\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:707)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:655)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:581)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:493)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      ")\n",
      "24/01/24 10:13:38 WARN scheduler.TaskSetManager: Lost task 136.0 in stage 23.0 (TID 669) (node33.cluster.tsc.uc3m.es executor 26): FetchFailed(BlockManagerId(1, node02.cluster.tsc.uc3m.es, 7337, None), shuffleId=2, mapIndex=4, mapId=174, reduceId=136, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage6.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer$$anon$1.hasNext(InMemoryRelation.scala:118)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:223)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1481)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1408)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1472)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1295)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:384)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:335)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.io.IOException: Connecting to node02.cluster.tsc.uc3m.es/10.0.13.22:7337 failed in the last 4750 ms, fail this connection directly\n",
      "\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)\n",
      "\tat org.apache.spark.network.shuffle.ExternalBlockStoreClient.lambda$fetchBlocks$0(ExternalBlockStoreClient.java:128)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of publications in the Research Portal without abstract after the matching: 24322\n"
     ]
    }
   ],
   "source": [
    "print('Number of publications in the Research Portal without abstract after the matching:', result_df.filter(\"Abstract IS NULL OR Abstract = ''\").count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474a04d-9681-44f9-8bdf-20e32d8536ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any null value\n",
    "null_check = result_df.select([F.count(F.when(F.col(column).isNull() | (F.trim(F.col(column)) == \"\"), column)).alias(column) for column in ['actID', 'Title', 'Abstract', 'DOI']])\n",
    "null_check.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ea964-df0e-474b-961b-66d60a8087f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any duplicated\n",
    "dup_check = result_df.groupBy(['actID', 'Title', 'Abstract', 'DOI']).agg(F.count(\"*\").alias(\"count\"))\n",
    "dup_check = dup_check.filter(\"count > 1\")\n",
    "dup_check.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd6da7-1af2-4fdc-a3b5-255617810f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete this duplicated instance\n",
    "result_df_no_duplicates = result_df.dropDuplicates([\"actID\", \"Title\", \"Abstract\", \"DOI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8289d60b-69d1-406e-b3d1-5db6d7bc872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a parquet the enriched datasets \n",
    "result_df_no_duplicates.write.parquet('export/usuarios_ml4ds/mbalairon/publications.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
